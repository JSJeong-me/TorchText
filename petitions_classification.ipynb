{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/TorchText/blob/main/petitions_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-xERacFRi7l",
        "outputId": "183746f3-3888-4ac0-8acf-f7a8518d3f21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==0.11.0\n",
            "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 30 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 102 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 112 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 122 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 127 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting argon2-cffi==20.1.0\n",
            "  Downloading argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.8.1)\n",
            "Collecting async-generator==1.10\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting attrs==20.3.0\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting bleach==3.2.1\n",
            "  Downloading bleach-3.2.1-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property==1.5.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.5.2)\n",
            "Collecting cachetools==4.2.0\n",
            "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
            "Collecting certifi==2020.12.5\n",
            "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 56.2 MB/s \n",
            "\u001b[?25hCollecting cffi==1.14.4\n",
            "  Downloading cffi-1.14.4-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
            "\u001b[K     |████████████████████████████████| 402 kB 61.6 MB/s \n",
            "\u001b[?25hCollecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 59.7 MB/s \n",
            "\u001b[?25hCollecting colorama==0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting Cython==0.29.14\n",
            "  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 42.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (4.4.2)\n",
            "Collecting defusedxml==0.6.0\n",
            "  Downloading defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.3)\n",
            "Collecting fsspec==0.8.5\n",
            "  Downloading fsspec-0.8.5-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting future==0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 79.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.4.0)\n",
            "Collecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting google-auth==1.24.0\n",
            "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 71.9 MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.2\n",
            "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 26)) (0.2.0)\n",
            "Collecting grpcio==1.34.0\n",
            "  Downloading grpcio-1.34.0-cp37-cp37m-manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (3.1.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (2.10)\n",
            "Collecting importlib-metadata==3.3.0\n",
            "  Downloading importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting ipykernel==5.4.2\n",
            "  Downloading ipykernel-5.4.2-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 59.6 MB/s \n",
            "\u001b[?25hCollecting ipython==7.4.0\n",
            "  Downloading ipython-7.4.0-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 60.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (0.2.0)\n",
            "Collecting ipywidgets==7.6.0\n",
            "  Downloading ipywidgets-7.6.0-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 59.1 MB/s \n",
            "\u001b[?25hCollecting jedi==0.18.0\n",
            "  Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting Jinja2==2.11.2\n",
            "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting joblib==1.0.0\n",
            "  Downloading joblib-1.0.0-py3-none-any.whl (302 kB)\n",
            "\u001b[K     |████████████████████████████████| 302 kB 56.9 MB/s \n",
            "\u001b[?25hCollecting JPype1==1.2.0\n",
            "  Downloading JPype1-1.2.0-cp37-cp37m-manylinux2010_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 59.9 MB/s \n",
            "\u001b[?25hCollecting jsonschema==3.2.0\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 40)) (1.0.0)\n",
            "Collecting jupyter-client==6.1.7\n",
            "  Downloading jupyter_client-6.1.7-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting jupyter-console==6.2.0\n",
            "  Downloading jupyter_console-6.2.0-py3-none-any.whl (22 kB)\n",
            "Collecting jupyter-core==4.7.0\n",
            "  Downloading jupyter_core-4.7.0-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-pygments==0.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 44)) (0.1.2)\n",
            "Collecting jupyterlab-widgets==1.0.0\n",
            "  Downloading jupyterlab_widgets-1.0.0-py3-none-any.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 59.8 MB/s \n",
            "\u001b[?25hCollecting Keras-Applications==1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 47)) (1.1.2)\n",
            "Collecting kiwisolver==1.3.1\n",
            "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.7 MB/s \n",
            "\u001b[?25hCollecting konlpy==0.5.2\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting lxml==4.6.2\n",
            "  Downloading lxml-4.6.2-cp37-cp37m-manylinux1_x86_64.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 43.3 MB/s \n",
            "\u001b[?25hCollecting Markdown==3.3.3\n",
            "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe==1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Collecting matplotlib==3.0.3\n",
            "  Downloading matplotlib-3.0.3-cp37-cp37m-manylinux1_x86_64.whl (13.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 54)) (0.8.4)\n",
            "Collecting nbclient==0.5.1\n",
            "  Downloading nbclient-0.5.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting nbconvert==6.0.7\n",
            "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
            "\u001b[K     |████████████████████████████████| 552 kB 34.7 MB/s \n",
            "\u001b[?25hCollecting nbformat==5.0.8\n",
            "  Downloading nbformat-5.0.8-py3-none-any.whl (172 kB)\n",
            "\u001b[K     |████████████████████████████████| 172 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio==1.4.3\n",
            "  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
            "Collecting notebook==6.1.6\n",
            "  Downloading notebook-6.1.6-py3-none-any.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 32.2 MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting oauthlib==3.1.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 63.1 MB/s \n",
            "\u001b[?25hCollecting packaging==20.8\n",
            "  Downloading packaging-20.8-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 63)) (1.1.5)\n",
            "Collecting pandocfilters==1.4.3\n",
            "  Downloading pandocfilters-1.4.3.tar.gz (16 kB)\n",
            "Collecting parso==0.8.1\n",
            "  Downloading parso-0.8.1-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 66)) (0.7.5)\n",
            "Collecting Pillow==8.0.1\n",
            "  Downloading Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.9.0\n",
            "  Downloading prometheus_client-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit==2.0.10\n",
            "  Downloading prompt_toolkit-2.0.10-py3-none-any.whl (340 kB)\n",
            "\u001b[K     |████████████████████████████████| 340 kB 68.1 MB/s \n",
            "\u001b[?25hCollecting protobuf==3.14.0\n",
            "  Downloading protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 71)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 72)) (0.2.8)\n",
            "Collecting pycparser==2.20\n",
            "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 67.8 MB/s \n",
            "\u001b[?25hCollecting Pygments==2.7.3\n",
            "  Downloading Pygments-2.7.3-py3-none-any.whl (950 kB)\n",
            "\u001b[K     |████████████████████████████████| 950 kB 55.2 MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting pyrsistent==0.17.3\n",
            "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 77)) (1.7.1)\n",
            "Collecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 65.0 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning==1.1.2\n",
            "  Downloading pytorch_lightning-1.1.2-py3-none-any.whl (671 kB)\n",
            "\u001b[K     |████████████████████████████████| 671 kB 58.3 MB/s \n",
            "\u001b[?25hCollecting pytz==2020.5\n",
            "  Downloading pytz-2020.5-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 58.4 MB/s \n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==300 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pywin32==300\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RNDaZjTRQ1f"
      },
      "source": [
        "# 2.1 크롤링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KQq-7QJRQ1h"
      },
      "source": [
        "[크롤링]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "Q08qhjJVRQ1i",
        "outputId": "628d75bb-1e02-40f2-ba9b-b736419ad0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sleep 90seconds. Count:584280,  Local Time:2021-12-31 06:57:32,  Data Length:7\n",
            "Sleep 90seconds. Count:584340,  Local Time:2021-12-31 06:59:25,  Data Length:66\n",
            "Sleep 90seconds. Count:584400,  Local Time:2021-12-31 07:01:15,  Data Length:125\n",
            "Sleep 90seconds. Count:584460,  Local Time:2021-12-31 07:02:47,  Data Length:125\n",
            "Sleep 90seconds. Count:584520,  Local Time:2021-12-31 07:04:19,  Data Length:125\n",
            "Sleep 90seconds. Count:584580,  Local Time:2021-12-31 07:05:51,  Data Length:125\n",
            "Sleep 90seconds. Count:584640,  Local Time:2021-12-31 07:07:42,  Data Length:183\n",
            "Sleep 90seconds. Count:584700,  Local Time:2021-12-31 07:09:14,  Data Length:183\n",
            "Sleep 90seconds. Count:584760,  Local Time:2021-12-31 07:10:46,  Data Length:183\n",
            "Sleep 90seconds. Count:584820,  Local Time:2021-12-31 07:12:23,  Data Length:193\n",
            "Sleep 90seconds. Count:584880,  Local Time:2021-12-31 07:13:56,  Data Length:193\n",
            "Sleep 90seconds. Count:584940,  Local Time:2021-12-31 07:15:28,  Data Length:193\n",
            "Sleep 90seconds. Count:585000,  Local Time:2021-12-31 07:17:01,  Data Length:193\n",
            "Sleep 90seconds. Count:585060,  Local Time:2021-12-31 07:18:34,  Data Length:193\n",
            "Sleep 90seconds. Count:585120,  Local Time:2021-12-31 07:20:06,  Data Length:193\n",
            "Sleep 90seconds. Count:585180,  Local Time:2021-12-31 07:21:38,  Data Length:193\n",
            "Sleep 90seconds. Count:585240,  Local Time:2021-12-31 07:23:10,  Data Length:193\n",
            "Sleep 90seconds. Count:585300,  Local Time:2021-12-31 07:24:42,  Data Length:193\n",
            "Sleep 90seconds. Count:585360,  Local Time:2021-12-31 07:26:15,  Data Length:193\n",
            "Sleep 90seconds. Count:585420,  Local Time:2021-12-31 07:27:47,  Data Length:193\n",
            "Sleep 90seconds. Count:585480,  Local Time:2021-12-31 07:29:19,  Data Length:193\n",
            "Sleep 90seconds. Count:585540,  Local Time:2021-12-31 07:31:00,  Data Length:222\n",
            "Sleep 90seconds. Count:585600,  Local Time:2021-12-31 07:32:49,  Data Length:281\n",
            "Sleep 90seconds. Count:585660,  Local Time:2021-12-31 07:34:30,  Data Length:308\n",
            "Sleep 90seconds. Count:585720,  Local Time:2021-12-31 07:36:08,  Data Length:319\n",
            "Sleep 90seconds. Count:585780,  Local Time:2021-12-31 07:37:41,  Data Length:319\n",
            "Sleep 90seconds. Count:585840,  Local Time:2021-12-31 07:39:32,  Data Length:378\n",
            "Sleep 90seconds. Count:585900,  Local Time:2021-12-31 07:41:25,  Data Length:437\n",
            "Sleep 90seconds. Count:585960,  Local Time:2021-12-31 07:43:17,  Data Length:494\n",
            "Sleep 90seconds. Count:586020,  Local Time:2021-12-31 07:45:08,  Data Length:554\n",
            "Sleep 90seconds. Count:586080,  Local Time:2021-12-31 07:46:41,  Data Length:554\n",
            "Sleep 90seconds. Count:586140,  Local Time:2021-12-31 07:48:21,  Data Length:584\n",
            "Sleep 90seconds. Count:586200,  Local Time:2021-12-31 07:50:14,  Data Length:643\n",
            "Sleep 90seconds. Count:586260,  Local Time:2021-12-31 07:51:46,  Data Length:643\n",
            "Sleep 90seconds. Count:586320,  Local Time:2021-12-31 07:53:18,  Data Length:643\n",
            "Sleep 90seconds. Count:586380,  Local Time:2021-12-31 07:54:50,  Data Length:643\n",
            "Sleep 90seconds. Count:586440,  Local Time:2021-12-31 07:56:23,  Data Length:643\n",
            "Sleep 90seconds. Count:586500,  Local Time:2021-12-31 07:57:55,  Data Length:643\n",
            "Sleep 90seconds. Count:586560,  Local Time:2021-12-31 07:59:27,  Data Length:643\n",
            "Sleep 90seconds. Count:586620,  Local Time:2021-12-31 08:00:59,  Data Length:643\n",
            "Sleep 90seconds. Count:586680,  Local Time:2021-12-31 08:02:36,  Data Length:653\n",
            "Sleep 90seconds. Count:586740,  Local Time:2021-12-31 08:04:18,  Data Length:681\n",
            "Sleep 90seconds. Count:586800,  Local Time:2021-12-31 08:05:55,  Data Length:692\n",
            "Sleep 90seconds. Count:586860,  Local Time:2021-12-31 08:07:39,  Data Length:728\n",
            "Sleep 90seconds. Count:586920,  Local Time:2021-12-31 08:09:16,  Data Length:738\n",
            "Sleep 90seconds. Count:586980,  Local Time:2021-12-31 08:10:52,  Data Length:748\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9f423ce406eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m               \u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m               +\",  Data Length:\"+ str(len(result)))        \n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup \n",
        "import time\n",
        "\n",
        "\n",
        "result = pd.DataFrame()                                    \n",
        "\n",
        "for i in range(584274, 595226):\n",
        "    URL = \"http://www1.president.go.kr/petitions/\"+str(i)\n",
        " \n",
        "    response = requests.get(URL)    \n",
        "    html = response.text                                   \n",
        "    soup = BeautifulSoup(html, 'html.parser')           \n",
        "\n",
        "    title = soup.find('h3', class_='petitionsView_title')\n",
        "    count = soup.find('span', class_='counter')           \n",
        "\n",
        "    for content in soup.select('div.petitionsView_write > div.View_write'):\n",
        "        content                                         \n",
        "\n",
        "    a=[]\n",
        "    for tag in soup.select('ul.petitionsView_info_list > li'): \n",
        "        a.append(tag.contents[1])\n",
        "\n",
        "    if len(a) != 0:\n",
        "        df1=pd.DataFrame({ 'start' : [a[1]],                \n",
        "                           'end' : [a[2]],                     \n",
        "                           'category' :  [a[0]],               \n",
        "                           'count' : [count.text],             \n",
        "                           'title': [title.text],              \n",
        "                           'content': [content.text.strip()[0:13000]]                              \n",
        "                         })\n",
        "\n",
        "        result=pd.concat([result, df1])                        \n",
        "        result.index = np.arange(len(result))             \n",
        "\n",
        "    if i % 60 == 0:                                        \n",
        "        print(\"Sleep 90seconds. Count:\" + str(i)           \n",
        "              +\",  Local Time:\"+ time.strftime('%Y-%m-%d', time.localtime(time.time()))\n",
        "              +\" \"+ time.strftime('%X', time.localtime(time.time()))\n",
        "              +\",  Data Length:\"+ str(len(result)))        \n",
        "        time.sleep(90) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MnsYfFqRQ1k"
      },
      "source": [
        "[크롤링 데이터 확인]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "sg_Fbac2RQ1k",
        "outputId": "65f541c3-a71e-4e3d-8b9e-61141fa17722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(748, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2ddd2e0e-c35d-4ed6-b0b7-6652b7488cb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>category</th>\n",
              "      <th>count</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>267</td>\n",
              "      <td>서울지방병무청 탈의실에 설치된 CCTV에 대한 진상규명을 요구한다. 또한 인권위의 ...</td>\n",
              "      <td>본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>경제민주화</td>\n",
              "      <td>271</td>\n",
              "      <td>주식시장 활성화 및 소액(개미)투자자 보호</td>\n",
              "      <td>우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>행정</td>\n",
              "      <td>198</td>\n",
              "      <td>교정기관의 민낮</td>\n",
              "      <td>억울한 일로 국민청원을 신청합니다.\\n\\r\\n 저는 **구치소 **교도관입니다.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>안전/환경</td>\n",
              "      <td>170</td>\n",
              "      <td>미세먼지 저감 대책</td>\n",
              "      <td>미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다.\\r\\n우리 일상에서 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>교통/건축/국토</td>\n",
              "      <td>2,127</td>\n",
              "      <td>악질세입자 방지를 위한 세입자보호법을 재정해주세요.</td>\n",
              "      <td>저는 우선 아이셋의 부모입니다.\\r\\n식구가 많은편이고 아이들이 성장함에 따라 집이...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ddd2e0e-c35d-4ed6-b0b7-6652b7488cb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ddd2e0e-c35d-4ed6-b0b7-6652b7488cb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ddd2e0e-c35d-4ed6-b0b7-6652b7488cb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        start  ...                                            content\n",
              "0  2020-01-02  ...  본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 ...\n",
              "1  2020-01-02  ...  우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저...\n",
              "2  2020-01-02  ...  억울한 일로 국민청원을 신청합니다.\\n\\r\\n 저는 **구치소 **교도관입니다.\\n...\n",
              "3  2020-01-02  ...  미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다.\\r\\n우리 일상에서 ...\n",
              "4  2020-01-02  ...  저는 우선 아이셋의 부모입니다.\\r\\n식구가 많은편이고 아이들이 성장함에 따라 집이...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "print(result.shape)\n",
        "\n",
        "df = result\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPmj7VWkRQ1l"
      },
      "source": [
        "[데이터 엑셀로 저장]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "3ka6r7PWjC_0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "65GEYQrQRQ1l"
      },
      "outputs": [],
      "source": [
        "df.to_csv('data/crawling.csv', index = False, encoding = 'utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IblBCJ85RQ1l"
      },
      "source": [
        "# 2.2 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "SnApXLdQRQ1m",
        "outputId": "42584271-5535-400f-ee09-5429d398542a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다. 하지만 투자매력이 없다고도 합니다.이렇게 말하는 이유가 어디 있습니까? 바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다.\\n\\r\\n지금은 투자매력이 없어서 그렇지,..우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과, 외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다. 그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다.\\n\\r\\n정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데,... 그렇지 못한 현실이 안타깝다고 생각합니다.\\r\\n국가가 지원해 돈 들이기가 어려우면,정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다. \\n\\r\\n그래서 저는 정부에 다음과 같이 청원합니다.\\r\\n주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서,...\\n\\r\\n첫째,주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오 \\n\\r\\n둘째,  코스닥 종목은 공매도 제외시켜 주세요.\\n\\r\\n공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다 \\n\\r\\n셋째, 거래시장의 주식거래세를 더 낮춰 주세요 \\n\\r\\n특히 개미(소액)투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다.\\n\\r\\n넷째, 중,장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요.\\n\\r\\n이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다.'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.loc[1]['content']  # 전처리 전"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IWPvQsYRQ1n"
      },
      "source": [
        "[전처리]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "i0NvJ7CCRQ1n"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_white_space(text):\n",
        "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "def remove_special_char(text):\n",
        "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "df.title = df.title.apply(remove_white_space)\n",
        "df.title = df.title.apply(remove_special_char)\n",
        "\n",
        "df.content = df.content.apply(remove_white_space)\n",
        "df.content = df.content.apply(remove_special_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "zVDNDE69RQ1o",
        "outputId": "0647472a-e71b-4d93-9495-5b4b35517177"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다  하지만 투자매력이 없다고도 합니다 이렇게 말하는 이유가 어디 있습니까  바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다    지금은 투자매력이 없어서 그렇지 우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과  외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다  그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다    정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데  그렇지 못한 현실이 안타깝다고 생각합니다   국가가 지원해 돈 들이기가 어려우면 정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다     그래서 저는 정부에 다음과 같이 청원합니다   주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서    첫째 주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오    둘째   코스닥 종목은 공매도 제외시켜 주세요    공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다    셋째  거래시장의 주식거래세를 더 낮춰 주세요    특히 개미 소액 투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다    넷째  중 장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요    이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다 '"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.loc[1]['content']  # 전처리 후"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC7YN9jRRQ1p"
      },
      "source": [
        "# 2.3 토크나이징 및 변수 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPmVQ8GrRQ1p"
      },
      "source": [
        "[토크나이징]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "SkSXfLg5jf9U",
        "outputId": "44605f3e-959d-4656-c322-3d40a6d11607"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Using cached konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Using cached beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bs4"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "LRdzoWR2RQ1q"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "df['title_token'] = df.title.apply(okt.morphs)\n",
        "df['content_token'] = df.content.apply(okt.nouns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl_NxvWjRQ1q"
      },
      "source": [
        "[파생변수 생성]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJzqthBxRQ1r",
        "outputId": "11bcce2c-967e-4659-d233-7166727680d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start            object\n",
            "end              object\n",
            "category         object\n",
            "count             int64\n",
            "title            object\n",
            "content          object\n",
            "title_token      object\n",
            "content_token    object\n",
            "token_final      object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "df['token_final'] = df.title_token + df.content_token\n",
        "\n",
        "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
        "\n",
        "print(df.dtypes)\n",
        "\n",
        "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "22csw9xBRQ1s"
      },
      "outputs": [],
      "source": [
        "df_drop = df[['token_final', 'label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bmVokp-GRQ1s",
        "outputId": "4e829e9e-84be-44b7-ab4c-ec9491895235"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4d94aaaa-9592-4d28-8e52-20c9999478d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_final</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d94aaaa-9592-4d28-8e52-20c9999478d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d94aaaa-9592-4d28-8e52-20c9999478d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d94aaaa-9592-4d28-8e52-20c9999478d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         token_final label\n",
              "0  [서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...    No\n",
              "1  [주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...    No\n",
              "2  [교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...    No\n",
              "3  [미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...    No\n",
              "4  [악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...   Yes"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df_drop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1So0M325RQ1t"
      },
      "source": [
        "[데이터 엑셀로 저장]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "wpucz5nbRQ1u"
      },
      "outputs": [],
      "source": [
        "df_drop.to_csv('data/df_drop.csv', index = False, encoding = 'utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqrKYMRARQ1u"
      },
      "source": [
        "# 2.4 단어 임베딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MTdHW6aRQ1v"
      },
      "source": [
        "[단어 임베딩]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p7eWT4-RQ1v",
        "outputId": "063f5d9a-80f5-48c3-a8cf-c201cd8dfaeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=14103, size=100, alpha=0.025)\n",
            "[('면제', 0.9990832805633545), ('권한', 0.9990674257278442), ('소장', 0.9990596771240234), ('정황', 0.9990448951721191), ('대가', 0.9990392327308655), ('도로', 0.9990255832672119), ('카드', 0.9990049600601196), ('담당자', 0.9990048408508301), ('토', 0.9990041255950928), ('내부', 0.9990000128746033)]\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "embedding_model = Word2Vec(df_drop['token_final'], \n",
        "                           sg = 1, # skip-gram\n",
        "                           size = 100, \n",
        "                           window = 2, \n",
        "                           min_count = 1, \n",
        "                           workers = 4\n",
        "                           )\n",
        "\n",
        "print(embedding_model)\n",
        "\n",
        "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
        "print(model_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Covs8el5RQ1w"
      },
      "source": [
        "[임베딩 모델 저장 및 로드]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uasub25lRQ1w",
        "outputId": "635bacef-4779-415e-9f58-e05b23595f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('면제', 0.9990832805633545), ('권한', 0.9990674257278442), ('소장', 0.9990596771240234), ('정황', 0.9990448951721191), ('대가', 0.9990392327308655), ('도로', 0.9990255832672119), ('카드', 0.9990049600601196), ('담당자', 0.9990048408508301), ('토', 0.9990041255950928), ('내부', 0.9990000128746033)]\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v') # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v') # 모델 로드\n",
        "\n",
        "model_result = loaded_model.most_similar(\"음주운전\")\n",
        "print(model_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slb2bUyhRQ1x"
      },
      "source": [
        "# 2.5 실험 설계"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QhjpQeiRQ1x"
      },
      "source": [
        "[데이터셋 분할 및 저장]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "mbCb_QyrRQ1y"
      },
      "outputs": [],
      "source": [
        "from numpy.random import RandomState\n",
        "\n",
        "rng = RandomState()\n",
        "\n",
        "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
        "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
        "\n",
        "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
        "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz_b9LEURQ1y"
      },
      "source": [
        "[Field클래스 정의]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install -U torchtext==0.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YunXiZ7WlSZD",
        "outputId": "29c78b93-9cee-41c3-e374-0e79b4e40036"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: torchtext==0.8.0 in /usr/local/lib/python3.7/dist-packages (0.8.0)',\n",
              " 'Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.10.0+cu111)',\n",
              " 'Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)',\n",
              " 'Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.62.3)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)',\n",
              " 'Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.10.8)',\n",
              " 'Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)',\n",
              " 'Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)',\n",
              " 'Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.10.0.2)']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "U9WtjtqaRQ1z"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "from torchtext.legacy.data import Field\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
        "    text = text.split(', ')\n",
        "    return text\n",
        "\n",
        "TEXT = Field(tokenize=tokenizer)\n",
        "LABEL = Field(sequential = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVEDr0SDRQ1z"
      },
      "source": [
        "[데이터 불러오기]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD9R2iTQRQ1z",
        "outputId": "f363cfce-e8b9-4db3-b442-ddd453789ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: ['악질', '세', '입자', '방지', '를', '위', '한', '세', '입자', '보호', '법', '을', '재정', '해주세요', '저', '우선', '아이', '셋', '부모', '식구', '편이', '아이', '집', '나름', '꿈', '가지', '좀더', '집', '분양', '아이', '학교', '문제', '분양', '집', '바로', '상황', '우선', '월세', '보증금', '백', '월', '보증금', '가격', '이유', '입자', '입자', '이후', '관리', '비', '한번', '걸', '알', '나름', '유주', '입자', '생활', '연락', '집주인', '관리', '비', '일일이', '체크', '웃기', '생각', '체납', '유주', '입자', '주시', '등', '한번', '주의', '알림', '관리소', '원망', '관리', '비', '보증금', '월세', '보증금', '멸후', '개월', '손해', '육박', '나름', '배려', '저희', '일주일', '뒤', '달뒤', '말', '전혀', '노력', '입자', '달', '달이', '지옥', '저희', '대출', '이자', '매', '마이너스', '통장', '이제', '더', '이상', '한계', '입자', '농락', '기분', '막상', '단전', '입자', '관리', '사무소', '입자', '보호', '법', '이야기', '이', '말', '사람', '난방', '수도', '전기', '저희', '빚', '요', '왜', '국가', '입자', '보호', '법', '는걸', '국가', '돈', '보호', '유주', '돈', '세입', '자만', '보호', '유주', '악한', '유주', '단전', '집주인', '누가', '부동산', '입자', '보호', '법', '수정', '금지', '입자', '보호', '법', '보증금', '상태', '적용', '입자', '보호', '법도', '예외', '법안', '명도', '소송도', '보증금', '경우', '제외', '보증금', '입자', '농간', '소유', '주의', '빚', '때', '소송', '진행', '법안', '시기', '정말', '법', '악용', '악질', '입자', '존재', '정말', '유주', '입장', '악질', '입자', '때문', '가슴앓이', '눈물', '경우', '사실', '꼭', '인지', '내', '집', '내', '살', '보지', '못', '새집', '생판', '피', '타인', '점거', '어이', '제때', '가지', '못', '이', '뭐', '상황', '한탄'] Yes\n",
            "Validation: ['서울', '지방', '병무청', '탈의실', '에', '설치', '된', '에', '대한', '진상', '규명', '을', '요구', '한', '다', '또한', '인권위', '의', '미온', '적', '대응', '을', '규탄', '한다', '본인', '경', '서울', '지방', '병무청', '제', '검사', '탈의실', '수', '것', '발견', '탈의실', '천장', '를', '발견', '것', '본인', '이', '경악', '탈의실', '를', '설치', '것', '개인정보보호법', '항', '위반', '사안', '법적', '문제', '촬영', '성폭력', '범죄', '처벌', '등', '관', '특례법', '항', '위반', '또한', '법적', '제일', '뿐', '개인', '자유', '침해', '성적', '수치심', '매우', '윤리', '문제', '불법', '카메라', '그', '자체', '문제', '공공기관', '탈의실', '불법', '비', '윤리', '카메라', '설치', '운영', '상황', '발생', '도대체', '한국', '정부', '인권', '무엇', '생각', '것', '발견', '직후', '인권위', '진정', '인권위', '현재', '조사', '진행', '답변', '병무청', '답변', '더', '이상', '답변', '것', '의미', '생각', '본인', '모', '커뮤니티', '이', '사실', '이후', '이슈', '화가', '병무청', '운영', '대답', '이', '대한', '조사', '경과', '발표', '사과', '책임', '대응', '전혀', '개인', '자유', '권리', '본질', '내용', '침해', '강제', '징집', '국제노동기구', '인정', '강제', '징용', '강제노동', '남성', '국가', '신체', '감시', '사건', '한국', '정부', '병역의무', '인권', '생각', '언제', '국가', '개인', '노예', '취급', '것', '백원', '시급', '강제', '폭력', '속', '것', '모자라', '이제', '어처구니', '일', '것', '경악', '수', '이', '본인', '위', '사실', '규탄', '아래', '대응', '요구', '서울', '지방', '병무청', '징병검사', '소', '탈의실', '설치', '경위', '운영', '여부', '관리', '역', '등', '대해', '낱낱이', '조사', '그', '진상', '병무청장', '지방', '병무청장', '이', '사건', '책임', '지고', '사퇴', '하라', '자진사퇴', '거부', '정부', '이', '파면', '이', '사건', '관련', '책임자', '담당자', '처벌', '병무', '정장', '명의', '사과문', '병무청', '사이트', '비롯', '온라인과', '전국', '신체검사', '소', '신체검사', '대상', '그', '사과', '내용', '알게', '사과', '내용', '조사', '경과', '언론', '배포', '이유', '인권위', '위', '민원', '무시', '조사', '책임자', '문책', '병무청', '제보자', '민원', '보복', '감시', '제보자', '민원', '적극', '보호', '한국', '정부', '남성', '강제', '징집', '강제노동', '대해', '최저임금', '배', '이상', '시급', '지급', '내', '현재', '징병제', '개혁', '강제', '징집', '강제', '징용', '강제노동', '폐지', '또한', '지금', '강제', '피해', '당한', '당사자', '사과', '합당', '피해', '보상금', '제공', '각주', '개인정보보호법', '제', '항', '제', '영상', '정보처리', '기기', '설치', '운영', '제한', '누구', '불', '특정', '다수', '이용', '목욕실', '화장실', '발', '한실', '탈의실', '등', '개인', '사생활', '현저', '침해', '우려', '장소', '내부', '볼', '수', '영상', '정보처리', '기기', '설치', '운영', '다만', '교도소', '정신', '보건', '시설', '등', '법령', '근거', '사람', '구금', '거나', '보호', '시설', '로서', '대통령령', '정', '시설', '대하', '여', '각주', '개인정보보호법', '제', '과태료', '항', '호', '다음', '각', '호의', '하나', '해당', '자', '이하', '과태료', '부과', '제', '항', '위반', '영상', '정보처리', '기기', '설치', '운영', '자', '각주', '성폭력', '범죄', '처벌', '등', '관', '특례법', '제', '카메라', '등', '이용', '촬영', '항', '카메라', '그', '이', '기능', '기계', '장치', '이용', '성적', '욕망', '수치심', '유발', '수', '사람', '신체', '촬영', '대상자', '의사', '촬영', '이하', '징역', '이하', '벌금', '처', '개정', '각주', '국제노동기구', '제', '호', '강제', '근로', '협약', '제', '호', '강제', '근로', '폐지', '협약', '제', '호', '정치', '견해', '기존', '정치', '사회', '제도', '사상', '반대', '견해', '발표', '것', '대한', '제재', '및', '정치', '억압', '교육', '수단', '나', '발전', '목적', '노동', '동원', '이용', '경우', '노동', '규제', '수단', '파업', '참가', '대한', '제재', '마', '인종', '사회', '민족', '종교', '차별', '대우', '수단'] No\n"
          ]
        }
      ],
      "source": [
        "from torchtext.legacy.data import TabularDataset\n",
        "\n",
        "train, validation = TabularDataset.splits(\n",
        "    path = 'data/',\n",
        "    train = 'train.csv',\n",
        "    validation = 'validation.csv',\n",
        "    format = 'csv',\n",
        "    fields = [('text', TEXT), ('label', LABEL)],\n",
        "    skip_header = True\n",
        ")\n",
        "\n",
        "print(\"Train:\", train[0].text,  train[0].label)\n",
        "print(\"Validation:\", validation[0].text, validation[0].label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9pArv5iRQ10"
      },
      "source": [
        "[단어장 및 DataLoader 정의]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyLCSobbRQ10",
        "outputId": "901aa5b0-08f1-4a2d-ba58-61fb03e72b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/14103 [00:00<?, ?it/s]Skipping token b'14103' with 1-dimensional vector [b'100']; likely a header\n",
            "100%|██████████| 14103/14103 [00:03<00:00, 4333.44it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 벡터의 개수와 차원 : torch.Size([12897, 100]) \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "\n",
        "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
        "\n",
        "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
        "LABEL.build_vocab(train)\n",
        "\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_iter, validation_iter = BucketIterator.splits(\n",
        "    datasets = (train, validation),\n",
        "    batch_size = 8,\n",
        "    device = device,\n",
        "    sort = False\n",
        ")\n",
        "\n",
        "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRUaXuXORQ11"
      },
      "source": [
        "# 2.6 TextCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DexQkkL3RQ11"
      },
      "source": [
        "[TextCNN 모델링]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "9GdRUVz2RQ11"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn   \n",
        "import torch.optim as optim \n",
        "import torch.nn.functional as F \n",
        "\n",
        "class TextCNN(nn.Module): \n",
        "    \n",
        "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
        "        \n",
        "        super(TextCNN, self).__init__()\n",
        "        \n",
        "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
        "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
        "    \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
        "        self.relu = nn.ReLU()                \n",
        "        self.dropout = nn.Dropout(0.4)         \n",
        "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
        "        \n",
        "    def forward(self, x):  \n",
        "      \n",
        "        emb_x = self.embed(x)           \n",
        "        emb_x = emb_x.unsqueeze(1)  \n",
        "\n",
        "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
        "\n",
        "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
        "        \n",
        "        fc_x = torch.cat(pool_x, dim=1) \n",
        "        fc_x = fc_x.squeeze(-1)       \n",
        "        fc_x = self.dropout(fc_x)         \n",
        "\n",
        "        logit = self.fc(fc_x)     \n",
        "        \n",
        "        return logit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbvxSyhvRQ12"
      },
      "source": [
        "[모델 학습 함수 정의]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "GOsTqGEiRQ12"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_itr, optimizer):\n",
        "    \n",
        "    model.train()                               \n",
        "    corrects, train_loss = 0.0,0        \n",
        "    \n",
        "    for batch in train_itr:\n",
        "        \n",
        "        text, target = batch.text, batch.label      \n",
        "        text = torch.transpose(text, 0, 1)          \n",
        "        target.data.sub_(1)                                 \n",
        "        text, target = text.to(device), target.to(device)  \n",
        "\n",
        "        optimizer.zero_grad()                           \n",
        "        logit = model(text)                         \n",
        "    \n",
        "        loss = F.cross_entropy(logit, target)   \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        \n",
        "        train_loss += loss.item()    \n",
        "        result = torch.max(logit,1)[1] \n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "        \n",
        "    train_loss /= len(train_itr.dataset)\n",
        "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
        "\n",
        "    return train_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEjjHXofRQ13"
      },
      "source": [
        "[모델 평가 함수 정의]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "id": "syFDLIuMRQ13"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, device, itr):\n",
        "    \n",
        "    model.eval()\n",
        "    corrects, test_loss = 0.0, 0\n",
        "\n",
        "    for batch in itr:\n",
        "        \n",
        "        text = batch.text\n",
        "        target = batch.label\n",
        "        text = torch.transpose(text, 0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "        \n",
        "        logit = model(text)\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        result = torch.max(logit,1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "\n",
        "    test_loss /= len(itr.dataset) \n",
        "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
        "    \n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdUrbyDeRQ13"
      },
      "source": [
        "[모델 학습 및 성능 확인]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3pMoOs5RQ13",
        "outputId": "689d185d-c2d6-4947-db24-49c9f4337264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextCNN(\n",
            "  (embed): Embedding(12897, 100)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
            ")\n",
            "Train Epoch: 1 \t Loss: 0.08652923487899296 \t Accuracy: 54.682273864746094%\n",
            "Valid Epoch: 1 \t Loss: 0.09036824107170105 \t Accuracy: 47.33333206176758%\n",
            "model saves at 47.33333206176758 accuracy\n",
            "-----------------------------------------------------------------------------\n",
            "Train Epoch: 2 \t Loss: 0.08575068862741209 \t Accuracy: 57.52508544921875%\n",
            "Valid Epoch: 2 \t Loss: 0.08894951105117797 \t Accuracy: 50.66666793823242%\n",
            "model saves at 50.66666793823242 accuracy\n",
            "-----------------------------------------------------------------------------\n",
            "Train Epoch: 3 \t Loss: 0.08596559043313348 \t Accuracy: 56.5217399597168%\n",
            "Valid Epoch: 3 \t Loss: 0.09074799378712972 \t Accuracy: 47.33333206176758%\n",
            "-----------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_test_acc = -1\n",
        "\n",
        "for epoch in range(1, 3+1):\n",
        " \n",
        "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
        "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
        "    \n",
        "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
        "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
        "        \n",
        "    if val_acc > best_test_acc:\n",
        "        best_test_acc = val_acc\n",
        "        \n",
        "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
        "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
        "    \n",
        "    print('-----------------------------------------------------------------------------')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "petitions_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}