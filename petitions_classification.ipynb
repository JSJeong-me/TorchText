{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/TorchText/blob/main/petitions_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-xERacFRi7l",
        "outputId": "5526b4b7-7cbe-42eb-d222-a5533e43228a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==0.11.0\n",
            "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
            "Collecting argon2-cffi==20.1.0\n",
            "  Using cached argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.8.1)\n",
            "Collecting async-generator==1.10\n",
            "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting attrs==20.3.0\n",
            "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Using cached beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "Collecting bleach==3.2.1\n",
            "  Using cached bleach-3.2.1-py2.py3-none-any.whl (145 kB)\n",
            "Requirement already satisfied: cached-property==1.5.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.5.2)\n",
            "Collecting cachetools==4.2.0\n",
            "  Using cached cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
            "Collecting certifi==2020.12.5\n",
            "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
            "Collecting cffi==1.14.4\n",
            "  Using cached cffi-1.14.4-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
            "Collecting chardet==4.0.0\n",
            "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "Collecting colorama==0.4.4\n",
            "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting cycler==0.10.0\n",
            "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting Cython==0.29.14\n",
            "  Using cached Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (4.4.2)\n",
            "Collecting defusedxml==0.6.0\n",
            "  Using cached defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.3)\n",
            "Collecting fsspec==0.8.5\n",
            "  Using cached fsspec-0.8.5-py3-none-any.whl (98 kB)\n",
            "Collecting future==0.18.2\n",
            "  Using cached future-0.18.2.tar.gz (829 kB)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.4.0)\n",
            "Collecting gensim==3.8.3\n",
            "  Using cached gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "Collecting google-auth==1.24.0\n",
            "  Using cached google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
            "Collecting google-auth-oauthlib==0.4.2\n",
            "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 26)) (0.2.0)\n",
            "Collecting grpcio==1.34.0\n",
            "  Using cached grpcio-1.34.0-cp37-cp37m-manylinux2014_x86_64.whl (3.9 MB)\n",
            "Requirement already satisfied: h5py==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (3.1.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (2.10)\n",
            "Collecting importlib-metadata==3.3.0\n",
            "  Using cached importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting ipykernel==5.4.2\n",
            "  Using cached ipykernel-5.4.2-py3-none-any.whl (119 kB)\n",
            "Collecting ipython==7.4.0\n",
            "  Using cached ipython-7.4.0-py3-none-any.whl (769 kB)\n",
            "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (0.2.0)\n",
            "Collecting ipywidgets==7.6.0\n",
            "  Using cached ipywidgets-7.6.0-py2.py3-none-any.whl (121 kB)\n",
            "Collecting jedi==0.18.0\n",
            "  Using cached jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Collecting Jinja2==2.11.2\n",
            "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
            "Collecting joblib==1.0.0\n",
            "  Using cached joblib-1.0.0-py3-none-any.whl (302 kB)\n",
            "Collecting JPype1==1.2.0\n",
            "  Using cached JPype1-1.2.0-cp37-cp37m-manylinux2010_x86_64.whl (453 kB)\n",
            "Collecting jsonschema==3.2.0\n",
            "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 40)) (1.0.0)\n",
            "Collecting jupyter-client==6.1.7\n",
            "  Using cached jupyter_client-6.1.7-py3-none-any.whl (108 kB)\n",
            "Collecting jupyter-console==6.2.0\n",
            "  Using cached jupyter_console-6.2.0-py3-none-any.whl (22 kB)\n",
            "Collecting jupyter-core==4.7.0\n",
            "  Using cached jupyter_core-4.7.0-py3-none-any.whl (82 kB)\n",
            "Requirement already satisfied: jupyterlab-pygments==0.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 44)) (0.1.2)\n",
            "Collecting jupyterlab-widgets==1.0.0\n",
            "  Using cached jupyterlab_widgets-1.0.0-py3-none-any.whl (243 kB)\n",
            "Collecting Keras-Applications==1.0.8\n",
            "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 47)) (1.1.2)\n",
            "Collecting kiwisolver==1.3.1\n",
            "  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting konlpy==0.5.2\n",
            "  Using cached konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "Collecting lxml==4.6.2\n",
            "  Using cached lxml-4.6.2-cp37-cp37m-manylinux1_x86_64.whl (5.5 MB)\n",
            "Collecting Markdown==3.3.3\n",
            "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
            "Collecting MarkupSafe==1.1.1\n",
            "  Using cached MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Collecting matplotlib==3.0.3\n",
            "  Using cached matplotlib-3.0.3-cp37-cp37m-manylinux1_x86_64.whl (13.0 MB)\n",
            "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 54)) (0.8.4)\n",
            "Collecting nbclient==0.5.1\n",
            "  Using cached nbclient-0.5.1-py3-none-any.whl (65 kB)\n",
            "Collecting nbconvert==6.0.7\n",
            "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
            "Collecting nbformat==5.0.8\n",
            "  Using cached nbformat-5.0.8-py3-none-any.whl (172 kB)\n",
            "Collecting nest-asyncio==1.4.3\n",
            "  Using cached nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
            "Collecting notebook==6.1.6\n",
            "  Using cached notebook-6.1.6-py3-none-any.whl (9.5 MB)\n",
            "Collecting numpy==1.19.4\n",
            "  Using cached numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "Collecting oauthlib==3.1.0\n",
            "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "Collecting packaging==20.8\n",
            "  Using cached packaging-20.8-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 63)) (1.1.5)\n",
            "Collecting pandocfilters==1.4.3\n",
            "  Using cached pandocfilters-1.4.3.tar.gz (16 kB)\n",
            "Collecting parso==0.8.1\n",
            "  Using cached parso-0.8.1-py2.py3-none-any.whl (93 kB)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 66)) (0.7.5)\n",
            "Collecting Pillow==8.0.1\n",
            "  Using cached Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "Collecting prometheus-client==0.9.0\n",
            "  Using cached prometheus_client-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "Collecting prompt-toolkit==2.0.10\n",
            "  Using cached prompt_toolkit-2.0.10-py3-none-any.whl (340 kB)\n",
            "Collecting protobuf==3.14.0\n",
            "  Using cached protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 71)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 72)) (0.2.8)\n",
            "Collecting pycparser==2.20\n",
            "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
            "Collecting Pygments==2.7.3\n",
            "  Using cached Pygments-2.7.3-py3-none-any.whl (950 kB)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting pyrsistent==0.17.3\n",
            "  Using cached pyrsistent-0.17.3.tar.gz (106 kB)\n",
            "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 77)) (1.7.1)\n",
            "Collecting python-dateutil==2.8.1\n",
            "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "Collecting pytorch-lightning==1.1.2\n",
            "  Using cached pytorch_lightning-1.1.2-py3-none-any.whl (671 kB)\n",
            "Collecting pytz==2020.5\n",
            "  Using cached pytz-2020.5-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==300 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pywin32==300\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RNDaZjTRQ1f"
      },
      "source": [
        "# 2.1 크롤링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KQq-7QJRQ1h"
      },
      "source": [
        "[크롤링]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q08qhjJVRQ1i",
        "outputId": "6df8d626-13db-4e18-a7d3-b4b9976c1638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sleep 90seconds. Count:584280,  Local Time:2022-01-15 12:58:17,  Data Length:0\n",
            "Sleep 90seconds. Count:584340,  Local Time:2022-01-15 12:58:43,  Data Length:60\n",
            "Sleep 90seconds. Count:584400,  Local Time:2022-01-15 12:59:57,  Data Length:60\n",
            "Sleep 90seconds. Count:584460,  Local Time:2022-01-15 13:00:12,  Data Length:60\n",
            "Sleep 90seconds. Count:584520,  Local Time:2022-01-15 13:00:26,  Data Length:60\n",
            "Sleep 90seconds. Count:584580,  Local Time:2022-01-15 13:00:41,  Data Length:60\n",
            "Sleep 90seconds. Count:584640,  Local Time:2022-01-15 13:00:55,  Data Length:60\n",
            "Sleep 90seconds. Count:584700,  Local Time:2022-01-15 13:01:10,  Data Length:60\n",
            "Sleep 90seconds. Count:584760,  Local Time:2022-01-15 13:01:24,  Data Length:60\n",
            "Sleep 90seconds. Count:584820,  Local Time:2022-01-15 13:01:39,  Data Length:60\n",
            "Sleep 90seconds. Count:584880,  Local Time:2022-01-15 13:01:53,  Data Length:60\n",
            "Sleep 90seconds. Count:584940,  Local Time:2022-01-15 13:02:08,  Data Length:60\n",
            "Sleep 90seconds. Count:585000,  Local Time:2022-01-15 13:02:23,  Data Length:60\n",
            "Sleep 90seconds. Count:585060,  Local Time:2022-01-15 13:02:37,  Data Length:60\n",
            "Sleep 90seconds. Count:585120,  Local Time:2022-01-15 13:02:52,  Data Length:60\n",
            "Sleep 90seconds. Count:585180,  Local Time:2022-01-15 13:03:06,  Data Length:60\n",
            "Sleep 90seconds. Count:585240,  Local Time:2022-01-15 13:03:21,  Data Length:60\n",
            "Sleep 90seconds. Count:585300,  Local Time:2022-01-15 13:03:35,  Data Length:60\n",
            "Sleep 90seconds. Count:585360,  Local Time:2022-01-15 13:03:50,  Data Length:60\n",
            "Sleep 90seconds. Count:585420,  Local Time:2022-01-15 13:04:05,  Data Length:60\n",
            "Sleep 90seconds. Count:585480,  Local Time:2022-01-15 13:04:20,  Data Length:60\n",
            "Sleep 90seconds. Count:585540,  Local Time:2022-01-15 13:04:34,  Data Length:60\n",
            "Sleep 90seconds. Count:585600,  Local Time:2022-01-15 13:04:49,  Data Length:60\n",
            "Sleep 90seconds. Count:585660,  Local Time:2022-01-15 13:05:03,  Data Length:60\n",
            "Sleep 90seconds. Count:585720,  Local Time:2022-01-15 13:05:18,  Data Length:60\n",
            "Sleep 90seconds. Count:585780,  Local Time:2022-01-15 13:05:32,  Data Length:60\n",
            "Sleep 90seconds. Count:585840,  Local Time:2022-01-15 13:05:47,  Data Length:60\n",
            "Sleep 90seconds. Count:585900,  Local Time:2022-01-15 13:06:02,  Data Length:60\n",
            "Sleep 90seconds. Count:585960,  Local Time:2022-01-15 13:06:16,  Data Length:60\n",
            "Sleep 90seconds. Count:586020,  Local Time:2022-01-15 13:06:31,  Data Length:60\n",
            "Sleep 90seconds. Count:586080,  Local Time:2022-01-15 13:06:45,  Data Length:60\n",
            "Sleep 90seconds. Count:586140,  Local Time:2022-01-15 13:07:00,  Data Length:60\n",
            "Sleep 90seconds. Count:586200,  Local Time:2022-01-15 13:07:19,  Data Length:68\n",
            "Sleep 90seconds. Count:586260,  Local Time:2022-01-15 13:07:34,  Data Length:68\n",
            "Sleep 90seconds. Count:586320,  Local Time:2022-01-15 13:07:49,  Data Length:68\n",
            "Sleep 90seconds. Count:586380,  Local Time:2022-01-15 13:08:03,  Data Length:68\n",
            "Sleep 90seconds. Count:586440,  Local Time:2022-01-15 13:08:18,  Data Length:68\n",
            "Sleep 90seconds. Count:586500,  Local Time:2022-01-15 13:08:33,  Data Length:68\n",
            "Sleep 90seconds. Count:586560,  Local Time:2022-01-15 13:08:47,  Data Length:68\n",
            "Sleep 90seconds. Count:586620,  Local Time:2022-01-15 13:09:02,  Data Length:68\n",
            "Sleep 90seconds. Count:586680,  Local Time:2022-01-15 13:09:16,  Data Length:68\n",
            "Sleep 90seconds. Count:586740,  Local Time:2022-01-15 13:09:31,  Data Length:68\n",
            "Sleep 90seconds. Count:586800,  Local Time:2022-01-15 13:09:46,  Data Length:68\n",
            "Sleep 90seconds. Count:586860,  Local Time:2022-01-15 13:10:01,  Data Length:68\n",
            "Sleep 90seconds. Count:586920,  Local Time:2022-01-15 13:10:16,  Data Length:68\n",
            "Sleep 90seconds. Count:586980,  Local Time:2022-01-15 13:10:30,  Data Length:68\n",
            "Sleep 90seconds. Count:587040,  Local Time:2022-01-15 13:10:45,  Data Length:68\n",
            "Sleep 90seconds. Count:587100,  Local Time:2022-01-15 13:10:59,  Data Length:68\n",
            "Sleep 90seconds. Count:587160,  Local Time:2022-01-15 13:11:14,  Data Length:68\n",
            "Sleep 90seconds. Count:587220,  Local Time:2022-01-15 13:11:28,  Data Length:68\n",
            "Sleep 90seconds. Count:587280,  Local Time:2022-01-15 13:11:43,  Data Length:68\n",
            "Sleep 90seconds. Count:587340,  Local Time:2022-01-15 13:11:57,  Data Length:68\n",
            "Sleep 90seconds. Count:587400,  Local Time:2022-01-15 13:12:12,  Data Length:68\n",
            "Sleep 90seconds. Count:587460,  Local Time:2022-01-15 13:12:26,  Data Length:68\n",
            "Sleep 90seconds. Count:587520,  Local Time:2022-01-15 13:12:41,  Data Length:68\n",
            "Sleep 90seconds. Count:587580,  Local Time:2022-01-15 13:12:56,  Data Length:68\n",
            "Sleep 90seconds. Count:587640,  Local Time:2022-01-15 13:13:10,  Data Length:68\n",
            "Sleep 90seconds. Count:587700,  Local Time:2022-01-15 13:13:25,  Data Length:68\n",
            "Sleep 90seconds. Count:587760,  Local Time:2022-01-15 13:13:39,  Data Length:68\n",
            "Sleep 90seconds. Count:587820,  Local Time:2022-01-15 13:13:54,  Data Length:68\n",
            "Sleep 90seconds. Count:587880,  Local Time:2022-01-15 13:14:09,  Data Length:68\n",
            "Sleep 90seconds. Count:587940,  Local Time:2022-01-15 13:14:24,  Data Length:68\n",
            "Sleep 90seconds. Count:588000,  Local Time:2022-01-15 13:14:39,  Data Length:68\n",
            "Sleep 90seconds. Count:588060,  Local Time:2022-01-15 13:14:53,  Data Length:68\n",
            "Sleep 90seconds. Count:588120,  Local Time:2022-01-15 13:15:12,  Data Length:75\n",
            "Sleep 90seconds. Count:588180,  Local Time:2022-01-15 13:15:26,  Data Length:75\n",
            "Sleep 90seconds. Count:588240,  Local Time:2022-01-15 13:15:41,  Data Length:75\n",
            "Sleep 90seconds. Count:588300,  Local Time:2022-01-15 13:17:01,  Data Length:133\n",
            "Sleep 90seconds. Count:588360,  Local Time:2022-01-15 13:17:15,  Data Length:133\n",
            "Sleep 90seconds. Count:588420,  Local Time:2022-01-15 13:17:34,  Data Length:140\n",
            "Sleep 90seconds. Count:588480,  Local Time:2022-01-15 13:18:54,  Data Length:199\n",
            "Sleep 90seconds. Count:588540,  Local Time:2022-01-15 13:19:12,  Data Length:227\n",
            "Sleep 90seconds. Count:588600,  Local Time:2022-01-15 13:20:28,  Data Length:230\n",
            "Sleep 90seconds. Count:588660,  Local Time:2022-01-15 13:21:47,  Data Length:289\n",
            "Sleep 90seconds. Count:588720,  Local Time:2022-01-15 13:22:05,  Data Length:307\n",
            "Sleep 90seconds. Count:588780,  Local Time:2022-01-15 13:22:19,  Data Length:307\n",
            "Sleep 90seconds. Count:588840,  Local Time:2022-01-15 13:22:34,  Data Length:310\n",
            "Sleep 90seconds. Count:588900,  Local Time:2022-01-15 13:23:57,  Data Length:368\n",
            "Sleep 90seconds. Count:588960,  Local Time:2022-01-15 13:24:19,  Data Length:425\n",
            "Sleep 90seconds. Count:589020,  Local Time:2022-01-15 13:24:33,  Data Length:425\n",
            "Sleep 90seconds. Count:589080,  Local Time:2022-01-15 13:24:48,  Data Length:425\n",
            "Sleep 90seconds. Count:589140,  Local Time:2022-01-15 13:26:09,  Data Length:484\n",
            "Sleep 90seconds. Count:589200,  Local Time:2022-01-15 13:26:30,  Data Length:542\n",
            "Sleep 90seconds. Count:589260,  Local Time:2022-01-15 13:26:45,  Data Length:542\n",
            "Sleep 90seconds. Count:589320,  Local Time:2022-01-15 13:26:59,  Data Length:542\n",
            "Sleep 90seconds. Count:589380,  Local Time:2022-01-15 13:27:14,  Data Length:542\n",
            "Sleep 90seconds. Count:589440,  Local Time:2022-01-15 13:27:28,  Data Length:542\n",
            "Sleep 90seconds. Count:589500,  Local Time:2022-01-15 13:27:43,  Data Length:542\n",
            "Sleep 90seconds. Count:589560,  Local Time:2022-01-15 13:27:58,  Data Length:542\n",
            "Sleep 90seconds. Count:589620,  Local Time:2022-01-15 13:28:13,  Data Length:542\n",
            "Sleep 90seconds. Count:589680,  Local Time:2022-01-15 13:28:28,  Data Length:542\n",
            "Sleep 90seconds. Count:589740,  Local Time:2022-01-15 13:28:42,  Data Length:542\n",
            "Sleep 90seconds. Count:589800,  Local Time:2022-01-15 13:28:58,  Data Length:542\n",
            "Sleep 90seconds. Count:589860,  Local Time:2022-01-15 13:29:13,  Data Length:542\n",
            "Sleep 90seconds. Count:589920,  Local Time:2022-01-15 13:29:27,  Data Length:542\n",
            "Sleep 90seconds. Count:589980,  Local Time:2022-01-15 13:29:46,  Data Length:549\n",
            "Sleep 90seconds. Count:590040,  Local Time:2022-01-15 13:30:06,  Data Length:557\n",
            "Sleep 90seconds. Count:590100,  Local Time:2022-01-15 13:30:21,  Data Length:557\n",
            "Sleep 90seconds. Count:590160,  Local Time:2022-01-15 13:30:36,  Data Length:557\n",
            "Sleep 90seconds. Count:590220,  Local Time:2022-01-15 13:30:50,  Data Length:557\n",
            "Sleep 90seconds. Count:590280,  Local Time:2022-01-15 13:31:05,  Data Length:557\n",
            "Sleep 90seconds. Count:590340,  Local Time:2022-01-15 13:31:20,  Data Length:557\n",
            "Sleep 90seconds. Count:590400,  Local Time:2022-01-15 13:31:35,  Data Length:557\n",
            "Sleep 90seconds. Count:590460,  Local Time:2022-01-15 13:31:49,  Data Length:557\n",
            "Sleep 90seconds. Count:590520,  Local Time:2022-01-15 13:32:04,  Data Length:557\n",
            "Sleep 90seconds. Count:590580,  Local Time:2022-01-15 13:32:18,  Data Length:557\n",
            "Sleep 90seconds. Count:590640,  Local Time:2022-01-15 13:32:33,  Data Length:557\n",
            "Sleep 90seconds. Count:590700,  Local Time:2022-01-15 13:32:51,  Data Length:567\n",
            "Sleep 90seconds. Count:590760,  Local Time:2022-01-15 13:33:06,  Data Length:567\n",
            "Sleep 90seconds. Count:590820,  Local Time:2022-01-15 13:33:20,  Data Length:567\n",
            "Sleep 90seconds. Count:590880,  Local Time:2022-01-15 13:33:41,  Data Length:576\n",
            "Sleep 90seconds. Count:590940,  Local Time:2022-01-15 13:33:56,  Data Length:576\n",
            "Sleep 90seconds. Count:591000,  Local Time:2022-01-15 13:34:11,  Data Length:576\n",
            "Sleep 90seconds. Count:591060,  Local Time:2022-01-15 13:34:25,  Data Length:576\n",
            "Sleep 90seconds. Count:591120,  Local Time:2022-01-15 13:34:40,  Data Length:576\n",
            "Sleep 90seconds. Count:591180,  Local Time:2022-01-15 13:34:54,  Data Length:576\n",
            "Sleep 90seconds. Count:591240,  Local Time:2022-01-15 13:35:09,  Data Length:576\n",
            "Sleep 90seconds. Count:591300,  Local Time:2022-01-15 13:35:24,  Data Length:576\n",
            "Sleep 90seconds. Count:591360,  Local Time:2022-01-15 13:35:38,  Data Length:576\n",
            "Sleep 90seconds. Count:591420,  Local Time:2022-01-15 13:35:53,  Data Length:576\n",
            "Sleep 90seconds. Count:591480,  Local Time:2022-01-15 13:36:08,  Data Length:576\n",
            "Sleep 90seconds. Count:591540,  Local Time:2022-01-15 13:36:22,  Data Length:576\n",
            "Sleep 90seconds. Count:591600,  Local Time:2022-01-15 13:36:36,  Data Length:576\n",
            "Sleep 90seconds. Count:591660,  Local Time:2022-01-15 13:36:51,  Data Length:576\n",
            "Sleep 90seconds. Count:591720,  Local Time:2022-01-15 13:37:05,  Data Length:576\n",
            "Sleep 90seconds. Count:591780,  Local Time:2022-01-15 13:37:20,  Data Length:576\n",
            "Sleep 90seconds. Count:591840,  Local Time:2022-01-15 13:38:45,  Data Length:628\n",
            "Sleep 90seconds. Count:591900,  Local Time:2022-01-15 13:39:04,  Data Length:635\n",
            "Sleep 90seconds. Count:591960,  Local Time:2022-01-15 13:40:24,  Data Length:688\n",
            "Sleep 90seconds. Count:592020,  Local Time:2022-01-15 13:40:39,  Data Length:692\n",
            "Sleep 90seconds. Count:592080,  Local Time:2022-01-15 13:40:54,  Data Length:692\n",
            "Sleep 90seconds. Count:592140,  Local Time:2022-01-15 13:41:08,  Data Length:692\n",
            "Sleep 90seconds. Count:592200,  Local Time:2022-01-15 13:41:26,  Data Length:697\n",
            "Sleep 90seconds. Count:592260,  Local Time:2022-01-15 13:42:40,  Data Length:697\n",
            "Sleep 90seconds. Count:592320,  Local Time:2022-01-15 13:42:55,  Data Length:697\n",
            "Sleep 90seconds. Count:592380,  Local Time:2022-01-15 13:43:09,  Data Length:697\n",
            "Sleep 90seconds. Count:592440,  Local Time:2022-01-15 13:43:24,  Data Length:697\n",
            "Sleep 90seconds. Count:592500,  Local Time:2022-01-15 13:43:49,  Data Length:713\n",
            "Sleep 90seconds. Count:592560,  Local Time:2022-01-15 13:44:03,  Data Length:714\n",
            "Sleep 90seconds. Count:592620,  Local Time:2022-01-15 13:45:18,  Data Length:714\n",
            "Sleep 90seconds. Count:592680,  Local Time:2022-01-15 13:45:33,  Data Length:714\n",
            "Sleep 90seconds. Count:592740,  Local Time:2022-01-15 13:45:48,  Data Length:714\n",
            "Sleep 90seconds. Count:592800,  Local Time:2022-01-15 13:46:07,  Data Length:722\n",
            "Sleep 90seconds. Count:592860,  Local Time:2022-01-15 13:46:21,  Data Length:722\n",
            "Sleep 90seconds. Count:592920,  Local Time:2022-01-15 13:46:36,  Data Length:722\n",
            "Sleep 90seconds. Count:592980,  Local Time:2022-01-15 13:46:50,  Data Length:722\n",
            "Sleep 90seconds. Count:593040,  Local Time:2022-01-15 13:47:05,  Data Length:722\n",
            "Sleep 90seconds. Count:593100,  Local Time:2022-01-15 13:47:20,  Data Length:722\n",
            "Sleep 90seconds. Count:593160,  Local Time:2022-01-15 13:47:34,  Data Length:722\n",
            "Sleep 90seconds. Count:593220,  Local Time:2022-01-15 13:47:49,  Data Length:722\n",
            "Sleep 90seconds. Count:593280,  Local Time:2022-01-15 13:48:03,  Data Length:722\n",
            "Sleep 90seconds. Count:593340,  Local Time:2022-01-15 13:48:18,  Data Length:722\n",
            "Sleep 90seconds. Count:593400,  Local Time:2022-01-15 13:48:33,  Data Length:722\n",
            "Sleep 90seconds. Count:593460,  Local Time:2022-01-15 13:48:47,  Data Length:722\n",
            "Sleep 90seconds. Count:593520,  Local Time:2022-01-15 13:49:02,  Data Length:722\n",
            "Sleep 90seconds. Count:593580,  Local Time:2022-01-15 13:49:17,  Data Length:722\n",
            "Sleep 90seconds. Count:593640,  Local Time:2022-01-15 13:49:31,  Data Length:722\n",
            "Sleep 90seconds. Count:593700,  Local Time:2022-01-15 13:49:46,  Data Length:722\n",
            "Sleep 90seconds. Count:593760,  Local Time:2022-01-15 13:50:01,  Data Length:722\n",
            "Sleep 90seconds. Count:593820,  Local Time:2022-01-15 13:50:15,  Data Length:722\n",
            "Sleep 90seconds. Count:593880,  Local Time:2022-01-15 13:50:30,  Data Length:722\n",
            "Sleep 90seconds. Count:593940,  Local Time:2022-01-15 13:50:45,  Data Length:722\n",
            "Sleep 90seconds. Count:594000,  Local Time:2022-01-15 13:50:59,  Data Length:722\n",
            "Sleep 90seconds. Count:594060,  Local Time:2022-01-15 13:51:14,  Data Length:722\n",
            "Sleep 90seconds. Count:594120,  Local Time:2022-01-15 13:51:29,  Data Length:722\n",
            "Sleep 90seconds. Count:594180,  Local Time:2022-01-15 13:51:43,  Data Length:722\n",
            "Sleep 90seconds. Count:594240,  Local Time:2022-01-15 13:51:58,  Data Length:722\n",
            "Sleep 90seconds. Count:594300,  Local Time:2022-01-15 13:52:13,  Data Length:722\n",
            "Sleep 90seconds. Count:594360,  Local Time:2022-01-15 13:52:28,  Data Length:722\n",
            "Sleep 90seconds. Count:594420,  Local Time:2022-01-15 13:52:42,  Data Length:722\n",
            "Sleep 90seconds. Count:594480,  Local Time:2022-01-15 13:52:57,  Data Length:722\n",
            "Sleep 90seconds. Count:594540,  Local Time:2022-01-15 13:53:11,  Data Length:722\n",
            "Sleep 90seconds. Count:594600,  Local Time:2022-01-15 13:53:26,  Data Length:722\n",
            "Sleep 90seconds. Count:594660,  Local Time:2022-01-15 13:53:40,  Data Length:722\n",
            "Sleep 90seconds. Count:594720,  Local Time:2022-01-15 13:53:55,  Data Length:722\n",
            "Sleep 90seconds. Count:594780,  Local Time:2022-01-15 13:54:09,  Data Length:722\n",
            "Sleep 90seconds. Count:594840,  Local Time:2022-01-15 13:54:24,  Data Length:722\n",
            "Sleep 90seconds. Count:594900,  Local Time:2022-01-15 13:54:38,  Data Length:722\n",
            "Sleep 90seconds. Count:594960,  Local Time:2022-01-15 13:54:53,  Data Length:722\n",
            "Sleep 90seconds. Count:595020,  Local Time:2022-01-15 13:55:07,  Data Length:722\n",
            "Sleep 90seconds. Count:595080,  Local Time:2022-01-15 13:55:22,  Data Length:722\n",
            "Sleep 90seconds. Count:595140,  Local Time:2022-01-15 13:55:36,  Data Length:722\n",
            "Sleep 90seconds. Count:595200,  Local Time:2022-01-15 13:55:51,  Data Length:722\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup \n",
        "import time\n",
        "\n",
        "\n",
        "result = pd.DataFrame()                                    \n",
        "\n",
        "for i in range(584274, 595226):\n",
        "    URL = \"http://www1.president.go.kr/petitions/\"+str(i)\n",
        " \n",
        "    response = requests.get(URL)    \n",
        "    html = response.text                                   \n",
        "    soup = BeautifulSoup(html, 'html.parser')           \n",
        "\n",
        "    title = soup.find('h3', class_='petitionsView_title')\n",
        "    count = soup.find('span', class_='counter')           \n",
        "\n",
        "    for content in soup.select('div.petitionsView_write > div.View_write'):\n",
        "        content                                         \n",
        "\n",
        "    a=[]\n",
        "    for tag in soup.select('ul.petitionsView_info_list > li'): \n",
        "        a.append(tag.contents[1])\n",
        "\n",
        "    if len(a) != 0:\n",
        "        df1=pd.DataFrame({ 'start' : [a[1]],                \n",
        "                           'end' : [a[2]],                     \n",
        "                           'category' :  [a[0]],               \n",
        "                           'count' : [count.text],             \n",
        "                           'title': [title.text],              \n",
        "                           'content': [content.text.strip()[0:13000]]                              \n",
        "                         })\n",
        "\n",
        "        result=pd.concat([result, df1])                        \n",
        "        result.index = np.arange(len(result))             \n",
        "\n",
        "    if i % 60 == 0:                                        \n",
        "        print(\"Sleep 90seconds. Count:\" + str(i)           \n",
        "              +\",  Local Time:\"+ time.strftime('%Y-%m-%d', time.localtime(time.time()))\n",
        "              +\" \"+ time.strftime('%X', time.localtime(time.time()))\n",
        "              +\",  Data Length:\"+ str(len(result)))        \n",
        "        time.sleep(10) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MnsYfFqRQ1k"
      },
      "source": [
        "[크롤링 데이터 확인]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "sg_Fbac2RQ1k",
        "outputId": "819bddd4-abfe-4451-f0a0-e10f52cbbbe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(722, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-52597bbd-174b-4946-a021-d063f1aecf71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>category</th>\n",
              "      <th>count</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>일자리</td>\n",
              "      <td>565</td>\n",
              "      <td>필리핀 인도네시아 베트남 무비자 제주도 관광 입국과 내륙5일 체류 반대합니다.</td>\n",
              "      <td>국민의 의견과 미래를 제대로 보지 못한  졸속 선심 외교 정책입니다. 되돌릴 방안을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>기타</td>\n",
              "      <td>314</td>\n",
              "      <td>군산보복폭행  피해자는 억울합니다.</td>\n",
              "      <td>2019.2.5일저녁7시40분경 남자친구와 남자친구가족들과 집앞치킨집에갔습니다.약 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>경제민주화</td>\n",
              "      <td>473</td>\n",
              "      <td>** 자산 운용 비리에 대하여 즉각적인 수사 진행을 해야 합니다.</td>\n",
              "      <td>국내 최대의 헤지 펀드운용사 '**자산운용'  경영자들의 도덕적 해이를 고발합니다....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>219,705</td>\n",
              "      <td>성 착취 사건인 'n번방 사건'의 근본적인 해결을 위한 국제 공조 수사를 청원합니다.</td>\n",
              "      <td>웹하드, 단톡방에 이은  'n번방'을 아십니까?\\n\\r\\n지난 2019년, 불법 영...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2020-02-01</td>\n",
              "      <td>정치개혁</td>\n",
              "      <td>1,872</td>\n",
              "      <td>《공수처장은 국민이 추천하고 국민이 뽑아야 합니다.》</td>\n",
              "      <td>통과한 공수처법 중,\\r\\n1.\"공수처장은 추천위원회 7명 중 6명의 찬성으로 결정...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52597bbd-174b-4946-a021-d063f1aecf71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52597bbd-174b-4946-a021-d063f1aecf71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52597bbd-174b-4946-a021-d063f1aecf71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        start  ...                                            content\n",
              "0  2020-01-02  ...  국민의 의견과 미래를 제대로 보지 못한  졸속 선심 외교 정책입니다. 되돌릴 방안을...\n",
              "1  2020-01-02  ...  2019.2.5일저녁7시40분경 남자친구와 남자친구가족들과 집앞치킨집에갔습니다.약 ...\n",
              "2  2020-01-02  ...  국내 최대의 헤지 펀드운용사 '**자산운용'  경영자들의 도덕적 해이를 고발합니다....\n",
              "3  2020-01-02  ...  웹하드, 단톡방에 이은  'n번방'을 아십니까?\\n\\r\\n지난 2019년, 불법 영...\n",
              "4  2020-01-02  ...  통과한 공수처법 중,\\r\\n1.\"공수처장은 추천위원회 7명 중 6명의 찬성으로 결정...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "print(result.shape)\n",
        "\n",
        "df = result\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPmj7VWkRQ1l"
      },
      "source": [
        "[데이터 엑셀로 저장]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "3ka6r7PWjC_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c298bf10-a9fd-462d-d84f-255fe0fb3cbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "65GEYQrQRQ1l"
      },
      "outputs": [],
      "source": [
        "df.to_csv('data/crawling.csv', index = False, encoding = 'utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IblBCJ85RQ1l"
      },
      "source": [
        "# 2.2 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "SnApXLdQRQ1m",
        "outputId": "26d74b5b-f573-4479-b3bd-df42d8596dec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2019.2.5일저녁7시40분경 남자친구와 남자친구가족들과 집앞치킨집에갔습니다.약 치킨을주문하고 기다리고 있던중 모르는남자한명이 우리자리앞까지 와서 훑어보고가서 술취해서 그려려니하고 대수롭지않게생각했습니다.약5분후쯤 다시우리자리로 오더니 갑자기남자친구이름까지 호명하며나오란것입니다..우린당황해서따라나갔고 나가자마자 어디론가데려가려고 따라오라는것을 안따갔고 그때부터 온갖욕설에 계속 본인후배에게 싸움을 부추겼습니다.우리는답답해서 도대체 이유도 모르는데 왜그러냐고?소리도질러보았지만 대답은커녕 욕만돌아올뿐..\\r\\n제가급해서112에신고하고 제폰으로 영상촬영을하자.가해자가 내폰을뺏으려고 내어깨를밀쳤고 두번째로 가해자후배또한 내부모욕까지하면 같은방법으로 어깨를밀쳤습니다.영상을찍다가 너무무섭고당행해서 중간에찍질 못해서한이맺칩니다.남자친구어머니는 옆에서지켜보시다가 놀래서 그만하라고한것뿐인데 가해자는 어머니께도 욕설을퍼붓는일도있었고 남자친구형님또한 우리를 막아주느라 가해자가미는바람에  밀려서 넘어질뻔한적도있었고 남자친구형수와 어린조카애들두명은 겁에질려 벌벌떨고 있었으며 우린아무런명분없이 당하고만 말았습니다.\\r\\n그런데 지금부터가 시작였습니다.영상에 맞았다는말과 정확히 어깨맞은장면이안나왔다며 증거가불충분했다고하고 경찰조사하던중 지역사회니 왠만하면 좋게합의하라는등..나는피해자가아니라는등..그자리없는이름을 데고 xxx알죠?다 아는사람이에요..라는 말을하고 비아발언도하였습니다.두사람이 키도크고덩치도커서 때리면 저쪽가해자는 맞아죽을것같다는등..어머니도욕먹으셨는데 고소가되냐고묻자..형사는 어머니도 이일에 끼어들이시게요?라는 말도안되는 말을했으며 나는 청문감사실가서 조사관을교채했습니다.하지만 교채해서 제조사를원했는데 대채어디서부터가 잘못된것인가요?바뀐형사도마찮가지였고 검사실넘어가서는 우리쪽을걱정해주시더니 중간에 조사관이바뀌고 또다시 우리되려 가해자가 된기분이었습니다.상대방은 20여년전에 여고생살인용의자공범입니다.전이미 알고있었기에 무서웠고 또다시보복을당할까바 두려웠습니다.전어깨진단3주에 수술을생각중이며 정신과치료또한 6개월째 치료중입니다.저는 보디빌더선수였습니다.한가정의 엄마입니다.하지만 그일로 선수생활도 못하게되었고 제꿈은 여기서끝이났습니다.자살시도도해봤지만 아이들생각에  또다시그런짓하면 나쁜엄마가되고 우리아이들마저 힘든생활을 하고살아왔습니다.남들처럼열심히살고 나보다 더어려운사람들돕고살아왔습니다.이유없는명분으로 시비걸고 증거불충분으로 한가정을 피패하게만들고 \\r\\n정상적인생활을 못하고살아왔는데 어떻게 법이그럽니까?정황들은 왜안봅니까?경찰차가 신고당시 왔는데도 불구하고 가해자는 온몸에문신을한채 위퉁을벗으며 우리에게 사지를찢어죽인다고까지 하였고 우린그말이 진심으로 다가왔습니다.왜냐하면 그사람은 이미 살인전과가있기때문에 진심으로다가왔습니다.결론은 1년간기다렸는데 증거불충분이라는 불기소라니요..어떻게이럴수있습니까?어떻게 아무런죄가없단말입니까?그러면 그가해자에게 무슨 신고를 해야 기소가 되는겁니까?이대로 풀린가해자는 기고만장하고 돌아다니고 있습니다.왜 피해자들은 계속 피해 돌아다녀야됩니까?파출소.경찰.검사쪽은 우리말을 들어주지않았습니다.이거 낱낱히 파헤쳐 주십시요.어디서부터 잘못됐는지..\\r\\n불기소이유처분서떼어보니 내가말하지도 않은말까지 적어놓고 조사관을 바뀌기전에 잘못된 내용들마저 적혀있었습니다.그게말이됩니까?왜 내가하지도않은말까지 적어논답말입니까?대한민국 경찰.검사들 어디믿고 신고하겠습니까?피해자는 계속피해를 당하고살아야된다는말입니까?아니면 그냥맞서싸워야된다는 말입니까?제발 제억울함을 풀어주세요.\\r\\n저희가족들은 작년 설날을 잊을수가없습니다.곧설날이 다가오는데 심장이 벌렁거려요.정신과약과 정형외과약으로 그만먹고살고 싶습니다.사건종결이됐는데 전아무런힘이없습니다.다른증거를 가져오라고하더군요.남자친구와 남자친구가족들은 증인이 왜안되는건가요?가해자는 절친과 치킨집이당골손님이라는 치킨집사장님이 증인섰다는데\\r\\n우리는 왜안되는건가요?우린 시시카메라도 보지못했습니다.가해자는이미봤다고합니다.어떻게우리나라는 피해자를위한법입니까?가해자를위한법입니까?꼭!사람이죽어야  믿나요?\\r\\n반드시 보복은 일어날껍니다.왜피해자가 피해다녀야되나요?\\r\\n보복당하면 그때또신고하라는 경찰들의 무책임한말...정말 본인가족이라도 이렇게 불기소로 종결시킬것인지 궁금합니다.지금까지\\r\\n있는사실대로말했으며 못한얘기도 많지만 나는피해자이고 이사건종결에대한 처음부텅잘못되었기에 군산이아닌 모르는조사관에게 다시받고싶습니다.군산이 지역사회라 가해자아버지가 교도관이셨다는말도들었습니다.그러면 힘없는 저는 억울하고 매번당하고만 살아야되나요?\\r\\n국민여러분 저는피해자입니다.더이상 다른피해자와 보복이이뤄지지않게 도와주세요.더 황당하건 분명히 나는신고하고 고소하시겠어요?라는경찰분말씀듣고 네~~라고대답하고 진술하고 그랬는데 난 고소인이 아니라 참고인으로 되있더라구요.남자친구는 고소인..나는 참고인..어떻게 이럴수가있는거죠?너무억울해서 매일악몽을 꿉니다.국민여러분 이일이 내일이라고 생각해보세요.제억울함을 풀어주세요..반드시 잘못된부분은 \\r\\n바로잡아서 가해자는 기고만장하게 돌아다니지않고 벌을받는게 맞다고생각합니다.평상시행실은 ?아이들에게 함부로욕하고 폭력적이라고 하네요..군산사람이면 손바닥이라 알만한사람은 알겠지요..\\r\\n가해자 지인분이 가해자에게 그냥하고싶은대로해~~니가깜방한두번가냐?라는말을 했답니다.녹취내용까지 첨부했는데 누락된부분들도 너무많았습니다.답답합니다.너무억울합니다.이게 합법적이라면 아무나지나가다가 시비걸고욕하고 시시티비안보이는 곳에서  때려도 아무런죄가아니라는 것입니까?그러면 경찰신고당시 경찰은 가해자 신원조회를하지않았습니다.파출소가서 저에게물어보는건 뭐죠?\\r\\n이게말이됩니까?국민여러분~~저는 억울합니다.이일이 내일이고 내가족일이라고 생각해봐주세요.저는힘도없고 백도없습니다.이렇게라도 제조사를해서라도 제가피해받은사실에 대한 죄값은 받아야된다고생각합니다.저 살인전과자를 어떻게 그냥둡니까?보복이 이뤄지기전에 잡고십습니다.또다른피해자가 나오지않길 바랄뿐이구요..국민여러분에 한표한표가 소중합니다..부탁드립니다.저의억울함을 풀어주세요.'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.loc[1]['content']  # 전처리 전"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IWPvQsYRQ1n"
      },
      "source": [
        "[전처리]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "i0NvJ7CCRQ1n"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_white_space(text):\n",
        "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "def remove_special_char(text):\n",
        "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "df.title = df.title.apply(remove_white_space)\n",
        "df.title = df.title.apply(remove_special_char)\n",
        "\n",
        "df.content = df.content.apply(remove_white_space)\n",
        "df.content = df.content.apply(remove_special_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "zVDNDE69RQ1o",
        "outputId": "0b042c79-d18c-4b59-8119-eb09d00572e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2019 2 5일저녁7시40분경 남자친구와 남자친구가족들과 집앞치킨집에갔습니다 약 치킨을주문하고 기다리고 있던중 모르는남자한명이 우리자리앞까지 와서 훑어보고가서 술취해서 그려려니하고 대수롭지않게생각했습니다 약5분후쯤 다시우리자리로 오더니 갑자기남자친구이름까지 호명하며나오란것입니다 우린당황해서따라나갔고 나가자마자 어디론가데려가려고 따라오라는것을 안따갔고 그때부터 온갖욕설에 계속 본인후배에게 싸움을 부추겼습니다 우리는답답해서 도대체 이유도 모르는데 왜그러냐고 소리도질러보았지만 대답은커녕 욕만돌아올뿐   제가급해서112에신고하고 제폰으로 영상촬영을하자 가해자가 내폰을뺏으려고 내어깨를밀쳤고 두번째로 가해자후배또한 내부모욕까지하면 같은방법으로 어깨를밀쳤습니다 영상을찍다가 너무무섭고당행해서 중간에찍질 못해서한이맺칩니다 남자친구어머니는 옆에서지켜보시다가 놀래서 그만하라고한것뿐인데 가해자는 어머니께도 욕설을퍼붓는일도있었고 남자친구형님또한 우리를 막아주느라 가해자가미는바람에  밀려서 넘어질뻔한적도있었고 남자친구형수와 어린조카애들두명은 겁에질려 벌벌떨고 있었으며 우린아무런명분없이 당하고만 말았습니다   그런데 지금부터가 시작였습니다 영상에 맞았다는말과 정확히 어깨맞은장면이안나왔다며 증거가불충분했다고하고 경찰조사하던중 지역사회니 왠만하면 좋게합의하라는등 나는피해자가아니라는등 그자리없는이름을 데고  알죠 다 아는사람이에요 라는 말을하고 비아발언도하였습니다 두사람이 키도크고덩치도커서 때리면 저쪽가해자는 맞아죽을것같다는등 어머니도욕먹으셨는데 고소가되냐고묻자 형사는 어머니도 이일에 끼어들이시게요 라는 말도안되는 말을했으며 나는 청문감사실가서 조사관을교채했습니다 하지만 교채해서 제조사를원했는데 대채어디서부터가 잘못된것인가요 바뀐형사도마찮가지였고 검사실넘어가서는 우리쪽을걱정해주시더니 중간에 조사관이바뀌고 또다시 우리되려 가해자가 된기분이었습니다 상대방은 20여년전에 여고생살인용의자공범입니다 전이미 알고있었기에 무서웠고 또다시보복을당할까바 두려웠습니다 전어깨진단3주에 수술을생각중이며 정신과치료또한 6개월째 치료중입니다 저는 보디빌더선수였습니다 한가정의 엄마입니다 하지만 그일로 선수생활도 못하게되었고 제꿈은 여기서끝이났습니다 자살시도도해봤지만 아이들생각에  또다시그런짓하면 나쁜엄마가되고 우리아이들마저 힘든생활을 하고살아왔습니다 남들처럼열심히살고 나보다 더어려운사람들돕고살아왔습니다 이유없는명분으로 시비걸고 증거불충분으로 한가정을 피패하게만들고   정상적인생활을 못하고살아왔는데 어떻게 법이그럽니까 정황들은 왜안봅니까 경찰차가 신고당시 왔는데도 불구하고 가해자는 온몸에문신을한채 위퉁을벗으며 우리에게 사지를찢어죽인다고까지 하였고 우린그말이 진심으로 다가왔습니다 왜냐하면 그사람은 이미 살인전과가있기때문에 진심으로다가왔습니다 결론은 1년간기다렸는데 증거불충분이라는 불기소라니요 어떻게이럴수있습니까 어떻게 아무런죄가없단말입니까 그러면 그가해자에게 무슨 신고를 해야 기소가 되는겁니까 이대로 풀린가해자는 기고만장하고 돌아다니고 있습니다 왜 피해자들은 계속 피해 돌아다녀야됩니까 파출소 경찰 검사쪽은 우리말을 들어주지않았습니다 이거 낱낱히 파헤쳐 주십시요 어디서부터 잘못됐는지   불기소이유처분서떼어보니 내가말하지도 않은말까지 적어놓고 조사관을 바뀌기전에 잘못된 내용들마저 적혀있었습니다 그게말이됩니까 왜 내가하지도않은말까지 적어논답말입니까 대한민국 경찰 검사들 어디믿고 신고하겠습니까 피해자는 계속피해를 당하고살아야된다는말입니까 아니면 그냥맞서싸워야된다는 말입니까 제발 제억울함을 풀어주세요   저희가족들은 작년 설날을 잊을수가없습니다 곧설날이 다가오는데 심장이 벌렁거려요 정신과약과 정형외과약으로 그만먹고살고 싶습니다 사건종결이됐는데 전아무런힘이없습니다 다른증거를 가져오라고하더군요 남자친구와 남자친구가족들은 증인이 왜안되는건가요 가해자는 절친과 치킨집이당골손님이라는 치킨집사장님이 증인섰다는데  우리는 왜안되는건가요 우린 시시카메라도 보지못했습니다 가해자는이미봤다고합니다 어떻게우리나라는 피해자를위한법입니까 가해자를위한법입니까 꼭 사람이죽어야  믿나요   반드시 보복은 일어날껍니다 왜피해자가 피해다녀야되나요   보복당하면 그때또신고하라는 경찰들의 무책임한말 정말 본인가족이라도 이렇게 불기소로 종결시킬것인지 궁금합니다 지금까지  있는사실대로말했으며 못한얘기도 많지만 나는피해자이고 이사건종결에대한 처음부텅잘못되었기에 군산이아닌 모르는조사관에게 다시받고싶습니다 군산이 지역사회라 가해자아버지가 교도관이셨다는말도들었습니다 그러면 힘없는 저는 억울하고 매번당하고만 살아야되나요   국민여러분 저는피해자입니다 더이상 다른피해자와 보복이이뤄지지않게 도와주세요 더 황당하건 분명히 나는신고하고 고소하시겠어요 라는경찰분말씀듣고 네 라고대답하고 진술하고 그랬는데 난 고소인이 아니라 참고인으로 되있더라구요 남자친구는 고소인 나는 참고인 어떻게 이럴수가있는거죠 너무억울해서 매일악몽을 꿉니다 국민여러분 이일이 내일이라고 생각해보세요 제억울함을 풀어주세요 반드시 잘못된부분은   바로잡아서 가해자는 기고만장하게 돌아다니지않고 벌을받는게 맞다고생각합니다 평상시행실은  아이들에게 함부로욕하고 폭력적이라고 하네요 군산사람이면 손바닥이라 알만한사람은 알겠지요   가해자 지인분이 가해자에게 그냥하고싶은대로해 니가깜방한두번가냐 라는말을 했답니다 녹취내용까지 첨부했는데 누락된부분들도 너무많았습니다 답답합니다 너무억울합니다 이게 합법적이라면 아무나지나가다가 시비걸고욕하고 시시티비안보이는 곳에서  때려도 아무런죄가아니라는 것입니까 그러면 경찰신고당시 경찰은 가해자 신원조회를하지않았습니다 파출소가서 저에게물어보는건 뭐죠   이게말이됩니까 국민여러분 저는 억울합니다 이일이 내일이고 내가족일이라고 생각해봐주세요 저는힘도없고 백도없습니다 이렇게라도 제조사를해서라도 제가피해받은사실에 대한 죄값은 받아야된다고생각합니다 저 살인전과자를 어떻게 그냥둡니까 보복이 이뤄지기전에 잡고십습니다 또다른피해자가 나오지않길 바랄뿐이구요 국민여러분에 한표한표가 소중합니다 부탁드립니다 저의억울함을 풀어주세요 '"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.loc[1]['content']  # 전처리 후"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC7YN9jRRQ1p"
      },
      "source": [
        "# 2.3 토크나이징 및 변수 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPmVQ8GrRQ1p"
      },
      "source": [
        "[토크나이징]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkSXfLg5jf9U",
        "outputId": "759c6707-8b22-40fa-b48b-2211741fa8e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "LRdzoWR2RQ1q"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "df['title_token'] = df.title.apply(okt.morphs)\n",
        "df['content_token'] = df.content.apply(okt.nouns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl_NxvWjRQ1q"
      },
      "source": [
        "[파생변수 생성]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJzqthBxRQ1r",
        "outputId": "f146e597-984a-4b79-8ad9-014048473414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start            object\n",
            "end              object\n",
            "category         object\n",
            "count             int64\n",
            "title            object\n",
            "content          object\n",
            "title_token      object\n",
            "content_token    object\n",
            "token_final      object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "df['token_final'] = df.title_token + df.content_token\n",
        "\n",
        "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
        "\n",
        "print(df.dtypes)\n",
        "\n",
        "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "22csw9xBRQ1s"
      },
      "outputs": [],
      "source": [
        "df_drop = df[['token_final', 'label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bmVokp-GRQ1s",
        "outputId": "8d43f409-2ef7-4890-9aee-95fd1d0958e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56970ea5-682e-4c6d-8118-ae599804171c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_final</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[필리핀, 인도네시아, 베트남, 무비, 자, 제주도, 관광, 입국, 과, 내륙, 5...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[군산, 보복, 폭행, 피해자, 는, 억울합니다, 남자친구, 남자친구, 가족, 집앞...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[자산, 운용, 비리, 에, 대하, 여, 즉각, 적, 인, 수사, 진행, 을, 해야...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[성, 착취, 사건, 인, 번방, 사건, 의, 근본, 적, 인, 해결, 을, 위, ...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[공, 수, 처, 장, 은, 국민, 이, 추천, 하고, 국민, 이, 뽑아야, 합니다...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56970ea5-682e-4c6d-8118-ae599804171c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56970ea5-682e-4c6d-8118-ae599804171c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56970ea5-682e-4c6d-8118-ae599804171c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         token_final label\n",
              "0  [필리핀, 인도네시아, 베트남, 무비, 자, 제주도, 관광, 입국, 과, 내륙, 5...    No\n",
              "1  [군산, 보복, 폭행, 피해자, 는, 억울합니다, 남자친구, 남자친구, 가족, 집앞...    No\n",
              "2  [자산, 운용, 비리, 에, 대하, 여, 즉각, 적, 인, 수사, 진행, 을, 해야...    No\n",
              "3  [성, 착취, 사건, 인, 번방, 사건, 의, 근본, 적, 인, 해결, 을, 위, ...   Yes\n",
              "4  [공, 수, 처, 장, 은, 국민, 이, 추천, 하고, 국민, 이, 뽑아야, 합니다...   Yes"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_drop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1So0M325RQ1t"
      },
      "source": [
        "[데이터 엑셀로 저장]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "wpucz5nbRQ1u"
      },
      "outputs": [],
      "source": [
        "df_drop.to_csv('data/df_drop.csv', index = False, encoding = 'utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqrKYMRARQ1u"
      },
      "source": [
        "# 2.4 단어 임베딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MTdHW6aRQ1v"
      },
      "source": [
        "[단어 임베딩]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p7eWT4-RQ1v",
        "outputId": "27fc4de0-56f4-4883-ea3f-6cd605b5f187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=13600, size=100, alpha=0.025)\n",
            "[('중국산', 0.9992846846580505), ('안보', 0.9992756247520447), ('난임', 0.9992634654045105), ('실로', 0.9992198944091797), ('울산', 0.9992125630378723), ('전주', 0.9992076754570007), ('대로', 0.9992074966430664), ('누나', 0.9992066621780396), ('친분', 0.999193549156189), ('인계', 0.9991801381111145)]\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "embedding_model = Word2Vec(df_drop['token_final'], \n",
        "                           sg = 1, # skip-gram\n",
        "                           size = 100, \n",
        "                           window = 2, \n",
        "                           min_count = 1, \n",
        "                           workers = 4\n",
        "                           )\n",
        "\n",
        "print(embedding_model)\n",
        "\n",
        "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
        "print(model_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Covs8el5RQ1w"
      },
      "source": [
        "[임베딩 모델 저장 및 로드]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uasub25lRQ1w",
        "outputId": "f6ddfbcb-6a7a-4cbf-d371-7016ccdf0bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('중국산', 0.9992846846580505), ('안보', 0.9992756247520447), ('난임', 0.9992634654045105), ('실로', 0.9992198944091797), ('울산', 0.9992125630378723), ('전주', 0.9992076754570007), ('대로', 0.9992074966430664), ('누나', 0.9992066621780396), ('친분', 0.999193549156189), ('인계', 0.9991801381111145)]\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v') # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v') # 모델 로드\n",
        "\n",
        "model_result = loaded_model.most_similar(\"음주운전\")\n",
        "print(model_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slb2bUyhRQ1x"
      },
      "source": [
        "# 2.5 실험 설계"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QhjpQeiRQ1x"
      },
      "source": [
        "[데이터셋 분할 및 저장]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "mbCb_QyrRQ1y"
      },
      "outputs": [],
      "source": [
        "from numpy.random import RandomState\n",
        "\n",
        "rng = RandomState()\n",
        "\n",
        "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
        "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
        "\n",
        "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
        "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz_b9LEURQ1y"
      },
      "source": [
        "[Field클래스 정의]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install -U torchtext==0.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YunXiZ7WlSZD",
        "outputId": "48b6c931-a25b-41ca-a39c-ffda23a328d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting torchtext==0.8.0',\n",
              " '  Using cached torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)',\n",
              " 'Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.10.1)',\n",
              " 'Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.62.3)',\n",
              " 'Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)',\n",
              " 'Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)',\n",
              " 'Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)',\n",
              " 'Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.10.8)',\n",
              " 'Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.10.0.2)',\n",
              " 'Installing collected packages: torchtext',\n",
              " '  Attempting uninstall: torchtext',\n",
              " '    Found existing installation: torchtext 0.11.1',\n",
              " '    Uninstalling torchtext-0.11.1:',\n",
              " '      Successfully uninstalled torchtext-0.11.1',\n",
              " 'Successfully installed torchtext-0.8.0']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==1.6 torchtext==0.7"
      ],
      "metadata": {
        "id": "y0LDuf6St8I5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/pytorch/text/archive/master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9IIRoWLv_nk",
        "outputId": "8e9df105-08e6-42fe-a66c-6964b8c0f1da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/pytorch/text/archive/master.zip\n",
            "  Using cached https://github.com/pytorch/text/archive/master.zip\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0a0) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0a0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0a0) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0a0) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0a0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0a0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0a0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0a0) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.11.0a0) (3.10.0.2)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for torchtext\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for torchtext\n",
            "Failed to build torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.8.0\n",
            "    Uninstalling torchtext-0.8.0:\n",
            "      Successfully uninstalled torchtext-0.8.0\n",
            "    Running setup.py install for torchtext ... \u001b[?25l\u001b[?25herror\n",
            "  Rolling back uninstall of torchtext\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/torchtext-0.8.0.dist-info/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~orchtext-0.8.0.dist-info\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/torchtext/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~orchtext\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-d3lhsrzo/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-d3lhsrzo/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-7i5h6rfx/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/torchtext Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "jv2QCMjwxX-x",
        "outputId": "a3fd02e2-3363-463a-b034-40548951bbbe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.1\n",
            "    Uninstalling torch-1.10.1:\n",
            "      Successfully uninstalled torch-1.10.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.6.0\n",
            "    Uninstalling torchtext-0.6.0:\n",
            "      Successfully uninstalled torchtext-0.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "U9WtjtqaRQ1z"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "from torchtext.legacy.data import Field\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
        "    text = text.split(', ')\n",
        "    return text\n",
        "\n",
        "TEXT = Field(tokenize=tokenizer)\n",
        "LABEL = Field(sequential = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVEDr0SDRQ1z"
      },
      "source": [
        "[데이터 불러오기]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD9R2iTQRQ1z",
        "outputId": "c4124444-3a96-449a-fbb5-4d9091bc42c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: ['에서', '일', '하고', '있는', '해외', '근로자', '들', '제발', '좀', '살려주세요', '저', '해외', '건설', '근로자', '하루하루', '일', '직원', '가족', '곳', '글', '처음', '글', '적지', '못', '관계자', '내', '가족', '일이', '생각', '한번', '대한민국', '청와대', '검색', '국민', '청원', '글자', '아래', '나라', '국민', '슬로건', '검색', '사람', '먼저', '문재인', '힘', '이란', '책', '제일', '먼저', '지금', '신랑', '생각', '벌렁', '거리', '가슴', '벌벌', '손', '꼭', '진짜', '절박', '심정', '글', '어디', '하소연', '여기', '글', '우리', '집', '가장', '위해', '내', '해', '줄', '수', '마지막', '일이', '생각', '마음', '저', '건설', '회사', '신랑', '결혼', '한지', '벌써', '직업', '특성', '회사', '발령', '이사도', '번', '말', '시간', '더', '딸', '지금', '중학교', '학년', '생후', '개월', '혼자', '지금', '두', '딸', '혼자', '결혼', '국내', '때', '회사', '일', '달', '번', '얼굴', '못', '벌써', '작년', '가을', '휴가', '때', '신랑', '건강', '문제', '해외', '말', '더', '그게', '제일', '후회', '성격', '고집', '세지', '워낙', '말', '책임감', '사람', '항상', '가정', '회사', '우선', '더', '이상', '휴가', '하루', '종일', '나', '자연인', '프로', '얼마나', '제', '구박', '지금', '곳', '일', '코로나', '담배', '쥐약', '차마', '담배', '좀', '말', '수', '그것', '낙', '요', '나라', '일', '둔부', '난', '종기', '하나', '제대로', '치료', '못', '달동', '안', '항생제', '휴가', '응급', '수술', '미련', '방치', '고름', '길이', '직장', '타고', '간', '상태', '의사', '큰일', '날', '뻔', '아주', '경우', '둔부', '살이', '기도', '전', '좌욕기', '하나', '또', '나라', '국가', '기업', '가정', '위해', '돈', '그', '심정', '당사자', '가족', '누가', '요', '그', '뒤', '코로나', '때문', '휴가', '못', '현장', '숙소', '현장', '숙소', '일만', '신랑', '언제', '볼', '수', '젠', '기약', '코로나', '때', '공기', '때', '애', '마음', '다른', '근로자', '가족', '마찬가지', '일', '것', '하루', '종일', '뉴스', '휴대폰', '우리나라', '중동', '코로나', '확', '진자', '얼마나', '또', '검색', '일상', '신랑', '일', '현장', '생각', '진짜', '가족', '정신병', '것', '저', '지금', '신랑', '직장', '지금', '우리', '가족', '위해', '고생', '지금', '일', '하든', '제', '우리', '가족', '각오', '자', '자', '글', '대통령', '정부', '입장', '기업', '입장', '이해', '안', '일단', '우리', '국민', '해외', '근로자', '국민', '기업', '국가', '생각', '것', '제', '간곡', '시대', '카톡', '로', '연락', '수', '얼마나', '다행', '어찌', '일인', '카톡', '확인', '이제', '대답', '코로나', '가족', '연락', '테', '한번', '신문', '기사', '더', '것', '얼마', '전', '코로나', '사망', '한국', '직원', '우리나라', '치료', '살', '수', '생각', '대통령', '애', '아빠', '시골', '연로', '시어머니', '몸', '안', '세', '데', '사시', '얼마나', '더', '사실', '막내아들', '애', '가족', '마음', '조금', '시오', '아침', '뉴스', '영사관', '공조', '전세기', '해외', '교민', '데리', '기사', '제발', '중동', '우리', '해외', '근로자', '안전', '최', '우선', '못', '기업', '위해', '우리', '정부', '적극', '시오', '중동', '코로나', '확', '진자', '하루', '하루하루', '공포', '불안', '환경', '고립', '현장', '일만', '해외', '근로자', '우리', '국민', '지금', '상황', '지금', '우리나라', '코로나', '해외', '유입', '자', '우리', '근로자', '우리', '근로자', '복귀', '희망', '자', '귀국', '해', '주시', '안', '요', '국가', '기업', '가정', '위해', '해외', '근로자', '목숨', '일', '그', '말로', '산업', '역군', '국민', '오늘', '신문', '방역', '모델', '국제', '사회', '적극', '공유', '개도국', '방역', '물품', '전달', '방역', '자부심', '한국', '선진국', '헤드라인', '장식', '기사', '화가', '무엇', '때문', '요', '현장', '특성', '개인', '마스크', '해도', '한계', '지금', '우리나라', '취하', '방역', '체계', '차이', '우리나라', '불법체류자', '외국', '정부', '말', '무시', '이태원', '발', '클럽', '확', '진자', '무료', '검사', '주지', '해외', '근로자', '우리나라', '진단', '키트', '검사', '해', '시오', '금전', '뉴스', '정부', '재난', '원금', '지급', '전', '국민', '지급', '재난', '원금', '속', '해외', '근로자', '달러', '포함', '정작', '그', '해당', '사항', '안', '그', '분', '세금', '우리', '근로자', '소외', '감', '그', '생각', '안전', '마지막', '글', '감사', '제', '마음', '조금', '바'] No\n",
            "Validation: ['군산', '보복', '폭행', '피해자', '는', '억울합니다', '남자친구', '남자친구', '가족', '집앞', '치킨', '집', '약', '치킨', '주문', '중', '남자', '명', '우리', '앞', '술취해', '려니', '생각', '약', '다시', '우리', '갑자기', '남자친구', '이름', '호명', '것', '우린', '황해', '어디', '론', '것', '그때', '욕설', '계속', '본인', '후배', '싸움', '우리', '도대체', '이유', '왜', '소리', '대답', '욕', '뿐', '제', '신고', '폰', '영상', '촬영', '하자', '가해자', '폰', '어깨', '두번째', '가해자', '후배', '또한', '내부', '모욕', '방법', '어깨', '영상', '행해', '중간', '이', '남자친구', '어머니', '옆', '것', '가해자', '어머니', '도', '욕설', '일도', '남자친구', '형님', '또한', '우리', '가해자', '가미', '바람', '남자친구', '형수', '조카', '애', '명', '겁', '벌벌', '우린', '명분', '당', '지금', '시작', '영상', '어깨', '장면', '이안', '증거', '경찰', '중', '지역', '사회', '합의', '등', '나', '피해자', '등', '자리', '이름', '데', '알', '사람', '비아', '발언', '사람', '키', '도크', '덩', '치도', '커서', '저쪽', '가해자', '등', '어머니', '고소', '형사', '어머니', '이일', '말', '말', '나', '청문', '감사', '실가', '사관', '교채', '교채', '조사', '채', '형사', '도마', '찮', '검', '사실', '우리', '쪽', '걱정', '중간', '사관', '우리', '가해자', '기분', '상대방', '년전', '여고생', '살인', '용의자', '공범', '전이', '보복', '바', '어깨', '진단', '주', '수술', '생각', '정신과', '치료', '또한', '개월', '치료', '저', '보디빌더', '가정', '엄마', '일로', '선수', '생활', '꿈', '여기', '끝', '자살', '시도', '아이', '생각', '짓', '엄마', '우리', '아이', '생활', '남', '살', '나', '더', '사람', '이유', '명분', '비걸', '증거불충분', '가정', '피패', '정상', '생활', '법', '정황', '왜안', '경찰차', '신고', '당시', '불구', '가해자', '온몸', '문신', '채', '위퉁', '우리', '사지', '우린', '말', '진심', '사람', '살인', '전과', '때문', '진심', '결론', '증거불충분', '불기소', '니요', '죄', '단말', '입', '가해자', '무슨', '신고', '기소', '겁', '가해자', '왜', '피해자', '계속', '피해', '파출소', '경찰', '검사', '쪽', '우리말', '거', '낱낱', '부터', '불기소', '이유', '처분', '떼', '어보', '사관', '기전', '내용', '그게', '말', '왜', '입', '대한민국', '경찰', '검사', '어디', '신고', '피해자', '계속', '피해', '말입', '그냥', '말입', '제발', '제', '가족', '작년', '설날', '곧', '설날', '심장', '벌렁', '거려', '정신과', '약과', '정형외과', '약', '사건', '종결', '힘', '증거', '남자친구', '남자친구', '가족', '증인', '왜', '가요', '가해자', '절친', '치킨', '골', '손님', '치킨', '집사', '장님', '증인', '우리', '왜', '가요', '우린', '카메라', '보지', '가해자', '우리나라', '피해자', '위', '법입', '가해자', '위', '법입', '꼭', '사람', '반드시', '보복', '껍니', '왜', '피해자', '피해', '보복', '그때', '또', '신고', '경찰', '정말', '본인', '가족', '불기소', '종결', '지금', '사실', '말', '못', '얘기', '나', '피해자', '사건', '종결', '대한', '처음', '부텅', '잘못', '군산', '사관', '다시', '군산', '지역', '사회', '가해자', '아버지', '교도관', '셨', '저', '매번', '국민', '여러분', '저', '피해자', '더', '이상', '피해자', '보복', '더', '나', '신고', '경찰', '말씀', '네', '대답', '진술', '난', '고소', '참고인', '남자친구', '고소', '나', '참고인', '악몽', '국민', '여러분', '이일이', '내일', '생각', '제', '반드시', '부분', '가해자', '벌', '생각', '평상시', '행실', '아이', '함부로', '욕', '폭력', '군산', '사람', '이면', '손바닥', '알', '사람', '가해자', '지인', '가해자', '그냥', '해', '니', '깜', '방한', '번가', '말', '녹취내용', '첨부', '누락', '부분', '이', '합법', '라면', '아무나', '비걸', '욕', '티비', '안보', '곳', '죄', '것입', '경찰', '신고', '당시', '경찰', '가해자', '조회', '파출소', '저', '뭐', '게말', '국민', '여러분', '저', '이일이', '내일', '가족', '일이', '생각', '저', '힘', '백도', '조사', '제', '피해', '사실', '대한', '죄값', '생각', '저', '살인', '전과자', '그냥', '보복', '기전', '피해자', '국민', '여러분', '표', '표', '의'] No\n"
          ]
        }
      ],
      "source": [
        "from torchtext.legacy.data import TabularDataset\n",
        "\n",
        "train, validation = TabularDataset.splits(\n",
        "    path = 'data/',\n",
        "    train = 'train.csv',\n",
        "    validation = 'validation.csv',\n",
        "    format = 'csv',\n",
        "    fields = [('text', TEXT), ('label', LABEL)],\n",
        "    skip_header = True\n",
        ")\n",
        "\n",
        "print(\"Train:\", train[0].text,  train[0].label)\n",
        "print(\"Validation:\", validation[0].text, validation[0].label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9pArv5iRQ10"
      },
      "source": [
        "[단어장 및 DataLoader 정의]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyLCSobbRQ10",
        "outputId": "e2b1ab23-a784-46f3-a36c-4c9e2e26576c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 벡터의 개수와 차원 : torch.Size([12483, 100]) \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "\n",
        "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
        "\n",
        "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
        "LABEL.build_vocab(train)\n",
        "\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_iter, validation_iter = BucketIterator.splits(\n",
        "    datasets = (train, validation),\n",
        "    batch_size = 8,\n",
        "    device = device,\n",
        "    sort = False\n",
        ")\n",
        "\n",
        "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRUaXuXORQ11"
      },
      "source": [
        "# 2.6 TextCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DexQkkL3RQ11"
      },
      "source": [
        "[TextCNN 모델링]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "id": "9GdRUVz2RQ11"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn   \n",
        "import torch.optim as optim \n",
        "import torch.nn.functional as F \n",
        "\n",
        "class TextCNN(nn.Module): \n",
        "    \n",
        "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
        "        \n",
        "        super(TextCNN, self).__init__()\n",
        "        \n",
        "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
        "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
        "    \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
        "        self.relu = nn.ReLU()                \n",
        "        self.dropout = nn.Dropout(0.4)         \n",
        "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
        "        \n",
        "    def forward(self, x):  \n",
        "      \n",
        "        emb_x = self.embed(x)           \n",
        "        emb_x = emb_x.unsqueeze(1)  \n",
        "\n",
        "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
        "\n",
        "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
        "        \n",
        "        fc_x = torch.cat(pool_x, dim=1) \n",
        "        fc_x = fc_x.squeeze(-1)       \n",
        "        fc_x = self.dropout(fc_x)         \n",
        "\n",
        "        logit = self.fc(fc_x)     \n",
        "        \n",
        "        return logit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbvxSyhvRQ12"
      },
      "source": [
        "[모델 학습 함수 정의]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "id": "GOsTqGEiRQ12"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_itr, optimizer):\n",
        "    \n",
        "    model.train()                               \n",
        "    corrects, train_loss = 0.0,0        \n",
        "    \n",
        "    for batch in train_itr:\n",
        "        \n",
        "        text, target = batch.text, batch.label      \n",
        "        text = torch.transpose(text, 0, 1)          \n",
        "        target.data.sub_(1)                                 \n",
        "        text, target = text.to(device), target.to(device)  \n",
        "\n",
        "        optimizer.zero_grad()                           \n",
        "        logit = model(text)                         \n",
        "    \n",
        "        loss = F.cross_entropy(logit, target)   \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        \n",
        "        train_loss += loss.item()    \n",
        "        result = torch.max(logit,1)[1] \n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "        \n",
        "    train_loss /= len(train_itr.dataset)\n",
        "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
        "\n",
        "    return train_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEjjHXofRQ13"
      },
      "source": [
        "[모델 평가 함수 정의]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "id": "syFDLIuMRQ13"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, device, itr):\n",
        "    \n",
        "    model.eval()\n",
        "    corrects, test_loss = 0.0, 0\n",
        "\n",
        "    for batch in itr:\n",
        "        \n",
        "        text = batch.text\n",
        "        target = batch.label\n",
        "        text = torch.transpose(text, 0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "        \n",
        "        logit = model(text)\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        result = torch.max(logit,1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "\n",
        "    test_loss /= len(itr.dataset) \n",
        "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
        "    \n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdUrbyDeRQ13"
      },
      "source": [
        "[모델 학습 및 성능 확인]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3pMoOs5RQ13",
        "outputId": "560b116d-631c-4f3f-cd33-4990303aa130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextCNN(\n",
            "  (embed): Embedding(12483, 100)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
            ")\n",
            "Train Epoch: 1 \t Loss: 0.08721571851354157 \t Accuracy: 55.017303466796875%\n",
            "Valid Epoch: 1 \t Loss: 0.08838119564784898 \t Accuracy: 48.61111068725586%\n",
            "model saves at 48.61111068725586 accuracy\n",
            "-----------------------------------------------------------------------------\n",
            "Train Epoch: 2 \t Loss: 0.08643734052931974 \t Accuracy: 57.612457275390625%\n",
            "Valid Epoch: 2 \t Loss: 0.08656969211167759 \t Accuracy: 48.61111068725586%\n",
            "-----------------------------------------------------------------------------\n",
            "Train Epoch: 3 \t Loss: 0.08298231078679173 \t Accuracy: 64.18685150146484%\n",
            "Valid Epoch: 3 \t Loss: 0.086115679393212 \t Accuracy: 52.77777862548828%\n",
            "model saves at 52.77777862548828 accuracy\n",
            "-----------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_test_acc = -1\n",
        "\n",
        "for epoch in range(1, 3+1):\n",
        " \n",
        "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
        "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
        "    \n",
        "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
        "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
        "        \n",
        "    if val_acc > best_test_acc:\n",
        "        best_test_acc = val_acc\n",
        "        \n",
        "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
        "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
        "    \n",
        "    print('-----------------------------------------------------------------------------')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "petitions_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}